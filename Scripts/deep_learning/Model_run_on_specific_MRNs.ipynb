{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/boses08/hype-prediction-longitudinal/ml/v2/src/Suparno Experiment\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from directories import *\n",
    "import numpy as np\n",
    "from parameters_config import Config\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(BASE_DIRECTORY.absolute())\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import OneHotEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer,KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH='/home/boses08/hype-prediction-longitudinal/ml'\n",
    "\n",
    "# DATA_FILE_PATH=\"../../data/raw/\"\n",
    "DATA_FILE_PATH = \"/home/boses08/hype-prediction-longitudinal/ml/data/raw_with_mrn/\"\n",
    "DATA_UNSUPERVISED_PATH = \"/home/boses08/hype-prediction-longitudinal/ml/v2/prepare_multi_modal_data/data/diag_drug_proc_365.parquet\"\n",
    "MRN_PATH = \"/home/boses08/hype-prediction-longitudinal/ml/v2/src/Suparno Experiment/data/selected_MRNs/ML_dataset_365.pkl\"\n",
    "\n",
    "DATA_FILE_PATH_PROCESS=\"/home/boses08/hype-prediction-longitudinal/ml/v2/src/Suparno Experiment/data/processed/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/boses08/hype-prediction-longitudinal/ml/data/v2/processed/\n",
      "/home/boses08/hype-prediction-longitudinal/ml/v2/model_parameters/initial_weights_all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/boses08/hype-prediction-longitudinal/ml/v2/model_parameters/initial_weights_all/initial_weights'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NO_OF_SUBSETS='all'\n",
    "version='v2'\n",
    "DATA_FILE_PATH_PROCESS=BASE_PATH+\"/data/\"+version+\"/processed/\"\n",
    "# DATA_FILE_PATH_PROCESS = '/mnt/hype_long/data'\n",
    "print(DATA_FILE_PATH_PROCESS)\n",
    "WEIGHTS_DIR=BASE_PATH+'/'+version+'/model_parameters/initial_weights_'+str(NO_OF_SUBSETS)\n",
    "print(WEIGHTS_DIR)\n",
    "initial_weights=WEIGHTS_DIR +'/initial_weights'\n",
    "initial_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_df_control):\n",
    "    train_df = df[df.train_test == 'train']\n",
    "    test_df = df[df.train_test == 'test']\n",
    "\n",
    "    if test_df_control_ratio is not None:\n",
    "        test_df_ht = test_df[test_df.HT == '1']\n",
    "        test_df_not_ht = test_df[test_df.HT == '0']\n",
    "        test_df_not_ht = test_df_not_ht.sample(test_df_control_ratio * test_df_ht.shape[0], random_state=42)\n",
    "        test_df = pd.concat([test_df_ht,test_df_not_ht])\n",
    "    \n",
    "    mrn_train = set(train_df['medical_record_number'])\n",
    "    mrn_test = set(test_df['medical_record_number'])\n",
    "    train_test_common = mrn_train.intersection(mrn_test)\n",
    "    train_df = train_df.drop(columns=['train_test', 'address_zip'])\n",
    "    test_df = test_df.drop(columns=['train_test', 'address_zip'])\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final dataframe shape after dropping NAs(266670, 316)\n",
      "HT               0      1\n",
      "train_test               \n",
      "test        153245   3269\n",
      "train        76528  33628\n"
     ]
    }
   ],
   "source": [
    "NA_removal_threshold = 80  ##atleast this many columns should have a non null value\n",
    "test_df_control_ratio = 2\n",
    "df =  pd.read_pickle(MRN_PATH)\n",
    "#Dataset_C['MRN'] = Dataset_C.index\n",
    "##Dataset_C.reset_index(level=0, inplace=True)\n",
    "df = df.dropna(axis=0, thresh = NA_removal_threshold)\n",
    "print(\"final dataframe shape after dropping NAs\" + str(df.shape))\n",
    "print(pd.crosstab(df.train_test, df.HT))\n",
    "MRN_train_df, MRN_test_df = train_test_split(df, test_df_control_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6538\n",
      "1    3269\n",
      "Name: HT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(MRN_test_df.HT.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mrn = list(MRN_train_df.medical_record_number)\n",
    "test_mrn = list(MRN_test_df.medical_record_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequence_data():\n",
    "    with open(DATA_FILE_PATH+\"data.txt\", \"rb\") as fp:\n",
    "        X = pickle.load(fp)\n",
    "\n",
    "    with open(DATA_FILE_PATH+ \"label.txt\", \"rb\") as fp:\n",
    "        y = pickle.load(fp)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(X, columns=['medical_record_number','sequence']), pd.DataFrame(y, columns=['target'])], axis=1)\n",
    "    return df\n",
    "\n",
    "def load_unsupervised_data(path):\n",
    "    df = pd.read_parquet(path)\n",
    "#     df = pd.read_pickle(path)\n",
    "    return df\n",
    "\n",
    "def filter_by_mrn(df,mrn_list):\n",
    "    return df[df.medical_record_number.isin(mrn_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data = load_sequence_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence_data = filter_by_mrn(sequence_data, train_mrn)\n",
    "test_sequence_data = filter_by_mrn(sequence_data, test_mrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110156, 3)\n",
      "(9807, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_sequence_data.shape)\n",
    "print(test_sequence_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence_data = train_sequence_data.drop(['medical_record_number','target'], axis = 1)\n",
    "test_sequence_data = test_sequence_data.drop(['medical_record_number','target'], axis = 1)\n",
    "\n",
    "train_sequence_data = np.asarray(train_sequence_data['sequence'])\n",
    "test_sequence_data = np.asarray(test_sequence_data['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After padding the sequence with the longest length the shape is: (110156, 150)\n",
      "340\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "train_sequence_data = tf.keras.preprocessing.sequence.pad_sequences(train_sequence_data, maxlen=Config.MAX_REVIEW_LENGTH, padding='pre', truncating='post')\n",
    "test_sequence_data = tf.keras.preprocessing.sequence.pad_sequences(test_sequence_data, maxlen=Config.MAX_REVIEW_LENGTH, padding='pre', truncating='post')\n",
    "\n",
    "print('After padding the sequence with the longest length the shape is:',train_sequence_data.shape)\n",
    "\n",
    "print(train_sequence_data.max())\n",
    "print(test_sequence_data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_data = load_unsupervised_data(DATA_UNSUPERVISED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unsupervised_data = filter_by_mrn(unsupervised_data, train_mrn)\n",
    "test_unsupervised_data = filter_by_mrn(unsupervised_data, test_mrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_unsupervised_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = [c for c in train_unsupervised_data.columns if train_unsupervised_data[c].dtype in [np.float, np.int] and c not in ['HT']]\n",
    "categorical_cols = [c for c in train_unsupervised_data.columns if train_unsupervised_data[c].dtype in [np.object] and c not in ['HT']]\n",
    "\n",
    "print(len(numerical_cols)+len(categorical_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boses08/.local/lib/python3.8/site-packages/pandas/core/frame.py:4160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_unsupervised_data.pop('HT').astype('int')\n",
    "test_labels = test_unsupervised_data.pop('HT').astype('int')\n",
    "\n",
    "train_unsupervised_data.drop(['medical_record_number'],inplace=True, axis = 1)\n",
    "test_unsupervised_data.drop(['medical_record_number'],inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "def impute_unsupervised_data(train_df, test_df):\n",
    "    categorical_cols = [c for c in train_df.columns if train_df[c].dtype in [np.object] and c not in ['HT']]\n",
    "    numerical_cols = [c for c in train_df.columns if train_df[c].dtype in [np.float, np.int] and c not in ['HT']]\n",
    "    print(\"Number of categorical features \" + str(len(categorical_cols)) + \" and number of numerical features \"+ str(len(numerical_cols)))\n",
    "    \n",
    "    ct = Pipeline([('ct',\n",
    "        ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', TargetEncoder(drop_invariant = True, handle_missing = 'return_nan', min_samples_leaf = 10), categorical_cols)])),\n",
    "        ('imputer' , SimpleImputer(missing_values=np.nan, strategy='median'))])\n",
    "\n",
    "    fitted_train= ct.fit(train_df,pd.to_numeric(train_labels))\n",
    "    \n",
    "    train_df = fitted_train.transform(train_df)\n",
    "    test_df = fitted_train.transform(test_df)\n",
    "    \n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features 26 and number of numerical features 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boses08/.local/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "train_unsupervised_data, test_unsupervised_data = impute_unsupervised_data(train_unsupervised_data,\n",
    "                                                                           test_unsupervised_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(train_unsupervised_data).any())\n",
    "print(np.isnan(test_unsupervised_data).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating the LSTM + AUX multi input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "tf.random.set_seed(seed=7)\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_1 (Embedding)         (None, 150, 100)     34100       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          80400       Embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 121)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 221)          0           lstm_1[0][0]                     \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            222         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 114,722\n",
      "Trainable params: 114,722\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import concatenate,Dense\n",
    "from keras.models import Model,load_model\n",
    "\n",
    "main_input = keras.Input(shape=(train_sequence_data.shape[1],), name='main_input') # dtype='int32'\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = layers.Embedding(Config.VOCAB_SIZE, Config.EMBEDDING_DIM, input_length=Config.MAX_REVIEW_LENGTH, name='Embedding_1')(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = layers.LSTM(100, name='lstm_1', dropout=0.5)(x)\n",
    "\n",
    "aux_input=keras.Input(shape=(train_unsupervised_data.shape[1],),name='aux_input')\n",
    "\n",
    "# We concatenate the lstm output to auxillary input\n",
    "x = concatenate([lstm_out, aux_input])\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, aux_input], outputs=[main_output])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=Config.METRICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.7104 - tp: 550.0000 - fp: 834.0000 - tn: 583.0000 - fn: 81.0000 - accuracy: 0.5532 - precision: 0.3974 - recall: 0.8716 - auc: 0.6799 - f1_score: 0.5459 - average_precision: 0.3974WARNING:tensorflow:From /home/boses08/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "38/38 [==============================] - 13s 353ms/step - loss: 0.5394 - tp: 9415.0000 - fp: 7846.0000 - tn: 45677.0000 - fn: 14171.0000 - accuracy: 0.7145 - precision: 0.5454 - recall: 0.3992 - auc: 0.7430 - f1_score: 0.4164 - average_precision: 0.5285 - val_loss: 0.4563 - val_tp: 5682.0000 - val_fp: 3015.0000 - val_tn: 19990.0000 - val_fn: 4360.0000 - val_accuracy: 0.7768 - val_precision: 0.6533 - val_recall: 0.5658 - val_auc: 0.8367 - val_f1_score: 0.6096 - val_average_precision: 0.6586\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 12s 320ms/step - loss: 0.4439 - tp: 13736.0000 - fp: 6902.0000 - tn: 46621.0000 - fn: 9850.0000 - accuracy: 0.7827 - precision: 0.6656 - recall: 0.5824 - auc: 0.8442 - f1_score: 0.6208 - average_precision: 0.6659 - val_loss: 0.4245 - val_tp: 6178.0000 - val_fp: 2762.0000 - val_tn: 20243.0000 - val_fn: 3864.0000 - val_accuracy: 0.7995 - val_precision: 0.6911 - val_recall: 0.6152 - val_auc: 0.8599 - val_f1_score: 0.6545 - val_average_precision: 0.6979\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 0.4206 - tp: 14382.0000 - fp: 6376.0000 - tn: 47147.0000 - fn: 9204.0000 - accuracy: 0.7979 - precision: 0.6928 - recall: 0.6098 - auc: 0.8633 - f1_score: 0.6481 - average_precision: 0.6933 - val_loss: 0.4109 - val_tp: 5559.0000 - val_fp: 2108.0000 - val_tn: 20897.0000 - val_fn: 4483.0000 - val_accuracy: 0.8006 - val_precision: 0.7251 - val_recall: 0.5536 - val_auc: 0.8718 - val_f1_score: 0.6294 - val_average_precision: 0.7302\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 0.4046 - tp: 14970.0000 - fp: 6118.0000 - tn: 47405.0000 - fn: 8616.0000 - accuracy: 0.8089 - precision: 0.7099 - recall: 0.6347 - auc: 0.8753 - f1_score: 0.6686 - average_precision: 0.7116 - val_loss: 0.3933 - val_tp: 6171.0000 - val_fp: 2247.0000 - val_tn: 20758.0000 - val_fn: 3871.0000 - val_accuracy: 0.8149 - val_precision: 0.7331 - val_recall: 0.6145 - val_auc: 0.8830 - val_f1_score: 0.6709 - val_average_precision: 0.7381\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 0.3909 - tp: 15365.0000 - fp: 5791.0000 - tn: 47732.0000 - fn: 8221.0000 - accuracy: 0.8183 - precision: 0.7263 - recall: 0.6514 - auc: 0.8858 - f1_score: 0.6864 - average_precision: 0.7281 - val_loss: 0.3844 - val_tp: 5901.0000 - val_fp: 1909.0000 - val_tn: 21096.0000 - val_fn: 4141.0000 - val_accuracy: 0.8169 - val_precision: 0.7556 - val_recall: 0.5876 - val_auc: 0.8905 - val_f1_score: 0.6638 - val_average_precision: 0.7605\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 12s 320ms/step - loss: 0.3786 - tp: 15796.0000 - fp: 5647.0000 - tn: 47876.0000 - fn: 7790.0000 - accuracy: 0.8257 - precision: 0.7367 - recall: 0.6697 - auc: 0.8942 - f1_score: 0.7010 - average_precision: 0.7376 - val_loss: 0.3701 - val_tp: 6981.0000 - val_fp: 2540.0000 - val_tn: 20465.0000 - val_fn: 3061.0000 - val_accuracy: 0.8305 - val_precision: 0.7332 - val_recall: 0.6952 - val_auc: 0.9003 - val_f1_score: 0.7162 - val_average_precision: 0.7379\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 0.3677 - tp: 16106.0000 - fp: 5389.0000 - tn: 48134.0000 - fn: 7480.0000 - accuracy: 0.8331 - precision: 0.7493 - recall: 0.6829 - auc: 0.9019 - f1_score: 0.7141 - average_precision: 0.7505 - val_loss: 0.3599 - val_tp: 6890.0000 - val_fp: 2268.0000 - val_tn: 20737.0000 - val_fn: 3152.0000 - val_accuracy: 0.8360 - val_precision: 0.7523 - val_recall: 0.6861 - val_auc: 0.9055 - val_f1_score: 0.7196 - val_average_precision: 0.7564\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 12s 320ms/step - loss: 0.3573 - tp: 16527.0000 - fp: 5211.0000 - tn: 48312.0000 - fn: 7059.0000 - accuracy: 0.8409 - precision: 0.7603 - recall: 0.7007 - auc: 0.9083 - f1_score: 0.7286 - average_precision: 0.7607 - val_loss: 0.3502 - val_tp: 7068.0000 - val_fp: 2147.0000 - val_tn: 20858.0000 - val_fn: 2974.0000 - val_accuracy: 0.8450 - val_precision: 0.7670 - val_recall: 0.7038 - val_auc: 0.9124 - val_f1_score: 0.7367 - val_average_precision: 0.7712\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 12s 319ms/step - loss: 0.3545 - tp: 16501.0000 - fp: 5108.0000 - tn: 48415.0000 - fn: 7085.0000 - accuracy: 0.8419 - precision: 0.7636 - recall: 0.6996 - auc: 0.9104 - f1_score: 0.7282 - average_precision: 0.7682 - val_loss: 0.3483 - val_tp: 7426.0000 - val_fp: 2375.0000 - val_tn: 20630.0000 - val_fn: 2616.0000 - val_accuracy: 0.8490 - val_precision: 0.7577 - val_recall: 0.7395 - val_auc: 0.9168 - val_f1_score: 0.7509 - val_average_precision: 0.7630\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 12s 321ms/step - loss: 0.3457 - tp: 16859.0000 - fp: 4865.0000 - tn: 48658.0000 - fn: 6727.0000 - accuracy: 0.8497 - precision: 0.7761 - recall: 0.7148 - auc: 0.9162 - f1_score: 0.7438 - average_precision: 0.7776 - val_loss: 0.3397 - val_tp: 7579.0000 - val_fp: 2416.0000 - val_tn: 20589.0000 - val_fn: 2463.0000 - val_accuracy: 0.8524 - val_precision: 0.7583 - val_recall: 0.7547 - val_auc: 0.9199 - val_f1_score: 0.7583 - val_average_precision: 0.7621\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 12s 321ms/step - loss: 0.3377 - tp: 16964.0000 - fp: 4693.0000 - tn: 48830.0000 - fn: 6622.0000 - accuracy: 0.8533 - precision: 0.7833 - recall: 0.7192 - auc: 0.9205 - f1_score: 0.7495 - average_precision: 0.7853 - val_loss: 0.3371 - val_tp: 8102.0000 - val_fp: 2726.0000 - val_tn: 20279.0000 - val_fn: 1940.0000 - val_accuracy: 0.8588 - val_precision: 0.7482 - val_recall: 0.8068 - val_auc: 0.9266 - val_f1_score: 0.7789 - val_average_precision: 0.7526\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 12s 321ms/step - loss: 0.3300 - tp: 17350.0000 - fp: 4621.0000 - tn: 48902.0000 - fn: 6236.0000 - accuracy: 0.8592 - precision: 0.7897 - recall: 0.7356 - auc: 0.9249 - f1_score: 0.7610 - average_precision: 0.7912 - val_loss: 0.3268 - val_tp: 6817.0000 - val_fp: 1446.0000 - val_tn: 21559.0000 - val_fn: 3225.0000 - val_accuracy: 0.8587 - val_precision: 0.8250 - val_recall: 0.6788 - val_auc: 0.9305 - val_f1_score: 0.7479 - val_average_precision: 0.8286\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 12s 321ms/step - loss: 0.3234 - tp: 17474.0000 - fp: 4477.0000 - tn: 49046.0000 - fn: 6112.0000 - accuracy: 0.8627 - precision: 0.7960 - recall: 0.7409 - auc: 0.9292 - f1_score: 0.7672 - average_precision: 0.7967 - val_loss: 0.3274 - val_tp: 6402.0000 - val_fp: 1249.0000 - val_tn: 21756.0000 - val_fn: 3640.0000 - val_accuracy: 0.8521 - val_precision: 0.8368 - val_recall: 0.6375 - val_auc: 0.9281 - val_f1_score: 0.7269 - val_average_precision: 0.8408\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.3202 - tp: 17552.0000 - fp: 4407.0000 - tn: 49116.0000 - fn: 6034.0000 - accuracy: 0.8646 - precision: 0.7993 - recall: 0.7442 - auc: 0.9306 - f1_score: 0.7701 - average_precision: 0.8017 - val_loss: 0.3165 - val_tp: 7775.0000 - val_fp: 2147.0000 - val_tn: 20858.0000 - val_fn: 2267.0000 - val_accuracy: 0.8664 - val_precision: 0.7836 - val_recall: 0.7742 - val_auc: 0.9328 - val_f1_score: 0.7812 - val_average_precision: 0.7879\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.3157 - tp: 17712.0000 - fp: 4320.0000 - tn: 49203.0000 - fn: 5874.0000 - accuracy: 0.8678 - precision: 0.8039 - recall: 0.7510 - auc: 0.9335 - f1_score: 0.7761 - average_precision: 0.8057 - val_loss: 0.3107 - val_tp: 7635.0000 - val_fp: 1711.0000 - val_tn: 21294.0000 - val_fn: 2407.0000 - val_accuracy: 0.8754 - val_precision: 0.8169 - val_recall: 0.7603 - val_auc: 0.9389 - val_f1_score: 0.7903 - val_average_precision: 0.8207\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.3091 - tp: 17896.0000 - fp: 4071.0000 - tn: 49452.0000 - fn: 5690.0000 - accuracy: 0.8734 - precision: 0.8147 - recall: 0.7588 - auc: 0.9373 - f1_score: 0.7856 - average_precision: 0.8156 - val_loss: 0.3037 - val_tp: 7835.0000 - val_fp: 1839.0000 - val_tn: 21166.0000 - val_fn: 2207.0000 - val_accuracy: 0.8776 - val_precision: 0.8099 - val_recall: 0.7802 - val_auc: 0.9405 - val_f1_score: 0.7970 - val_average_precision: 0.8130\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.3025 - tp: 18036.0000 - fp: 3947.0000 - tn: 49576.0000 - fn: 5550.0000 - accuracy: 0.8768 - precision: 0.8205 - recall: 0.7647 - auc: 0.9407 - f1_score: 0.7913 - average_precision: 0.8218 - val_loss: 0.2990 - val_tp: 7986.0000 - val_fp: 1819.0000 - val_tn: 21186.0000 - val_fn: 2056.0000 - val_accuracy: 0.8827 - val_precision: 0.8145 - val_recall: 0.7953 - val_auc: 0.9441 - val_f1_score: 0.8070 - val_average_precision: 0.8180\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2980 - tp: 18141.0000 - fp: 3838.0000 - tn: 49685.0000 - fn: 5445.0000 - accuracy: 0.8796 - precision: 0.8254 - recall: 0.7691 - auc: 0.9429 - f1_score: 0.7961 - average_precision: 0.8261 - val_loss: 0.2944 - val_tp: 7879.0000 - val_fp: 1806.0000 - val_tn: 21199.0000 - val_fn: 2163.0000 - val_accuracy: 0.8799 - val_precision: 0.8135 - val_recall: 0.7846 - val_auc: 0.9425 - val_f1_score: 0.7999 - val_average_precision: 0.8154\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2938 - tp: 18258.0000 - fp: 3808.0000 - tn: 49715.0000 - fn: 5328.0000 - accuracy: 0.8815 - precision: 0.8274 - recall: 0.7741 - auc: 0.9450 - f1_score: 0.7995 - average_precision: 0.8286 - val_loss: 0.2899 - val_tp: 7645.0000 - val_fp: 1454.0000 - val_tn: 21551.0000 - val_fn: 2397.0000 - val_accuracy: 0.8835 - val_precision: 0.8402 - val_recall: 0.7613 - val_auc: 0.9459 - val_f1_score: 0.8002 - val_average_precision: 0.8427\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2879 - tp: 18462.0000 - fp: 3700.0000 - tn: 49823.0000 - fn: 5124.0000 - accuracy: 0.8856 - precision: 0.8330 - recall: 0.7828 - auc: 0.9475 - f1_score: 0.8069 - average_precision: 0.8333 - val_loss: 0.2849 - val_tp: 7833.0000 - val_fp: 1487.0000 - val_tn: 21518.0000 - val_fn: 2209.0000 - val_accuracy: 0.8882 - val_precision: 0.8405 - val_recall: 0.7800 - val_auc: 0.9498 - val_f1_score: 0.8104 - val_average_precision: 0.8429\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2836 - tp: 18490.0000 - fp: 3623.0000 - tn: 49900.0000 - fn: 5096.0000 - accuracy: 0.8869 - precision: 0.8362 - recall: 0.7839 - auc: 0.9495 - f1_score: 0.8092 - average_precision: 0.8366 - val_loss: 0.2850 - val_tp: 8434.0000 - val_fp: 2060.0000 - val_tn: 20945.0000 - val_fn: 1608.0000 - val_accuracy: 0.8890 - val_precision: 0.8037 - val_recall: 0.8399 - val_auc: 0.9506 - val_f1_score: 0.8229 - val_average_precision: 0.8069\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2805 - tp: 18596.0000 - fp: 3580.0000 - tn: 49943.0000 - fn: 4990.0000 - accuracy: 0.8889 - precision: 0.8386 - recall: 0.7884 - auc: 0.9510 - f1_score: 0.8117 - average_precision: 0.8401 - val_loss: 0.2773 - val_tp: 8107.0000 - val_fp: 1645.0000 - val_tn: 21360.0000 - val_fn: 1935.0000 - val_accuracy: 0.8917 - val_precision: 0.8313 - val_recall: 0.8073 - val_auc: 0.9519 - val_f1_score: 0.8207 - val_average_precision: 0.8335\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2780 - tp: 18688.0000 - fp: 3594.0000 - tn: 49929.0000 - fn: 4898.0000 - accuracy: 0.8899 - precision: 0.8387 - recall: 0.7923 - auc: 0.9520 - f1_score: 0.8144 - average_precision: 0.8407 - val_loss: 0.2744 - val_tp: 8061.0000 - val_fp: 1520.0000 - val_tn: 21485.0000 - val_fn: 1981.0000 - val_accuracy: 0.8941 - val_precision: 0.8414 - val_recall: 0.8027 - val_auc: 0.9532 - val_f1_score: 0.8232 - val_average_precision: 0.8440\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2714 - tp: 18848.0000 - fp: 3342.0000 - tn: 50181.0000 - fn: 4738.0000 - accuracy: 0.8952 - precision: 0.8494 - recall: 0.7991 - auc: 0.9555 - f1_score: 0.8237 - average_precision: 0.8501 - val_loss: 0.2696 - val_tp: 8058.0000 - val_fp: 1425.0000 - val_tn: 21580.0000 - val_fn: 1984.0000 - val_accuracy: 0.8968 - val_precision: 0.8497 - val_recall: 0.8024 - val_auc: 0.9557 - val_f1_score: 0.8268 - val_average_precision: 0.8519\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2679 - tp: 18983.0000 - fp: 3387.0000 - tn: 50136.0000 - fn: 4603.0000 - accuracy: 0.8964 - precision: 0.8486 - recall: 0.8048 - auc: 0.9562 - f1_score: 0.8260 - average_precision: 0.8494 - val_loss: 0.2671 - val_tp: 7763.0000 - val_fp: 1173.0000 - val_tn: 21832.0000 - val_fn: 2279.0000 - val_accuracy: 0.8955 - val_precision: 0.8687 - val_recall: 0.7731 - val_auc: 0.9556 - val_f1_score: 0.8189 - val_average_precision: 0.8698\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2651 - tp: 18964.0000 - fp: 3286.0000 - tn: 50237.0000 - fn: 4622.0000 - accuracy: 0.8974 - precision: 0.8523 - recall: 0.8040 - auc: 0.9574 - f1_score: 0.8272 - average_precision: 0.8533 - val_loss: 0.2659 - val_tp: 8442.0000 - val_fp: 1817.0000 - val_tn: 21188.0000 - val_fn: 1600.0000 - val_accuracy: 0.8966 - val_precision: 0.8229 - val_recall: 0.8407 - val_auc: 0.9569 - val_f1_score: 0.8338 - val_average_precision: 0.8262\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2617 - tp: 19201.0000 - fp: 3276.0000 - tn: 50247.0000 - fn: 4385.0000 - accuracy: 0.9006 - precision: 0.8543 - recall: 0.8141 - auc: 0.9588 - f1_score: 0.8332 - average_precision: 0.8558 - val_loss: 0.2631 - val_tp: 8397.0000 - val_fp: 1505.0000 - val_tn: 21500.0000 - val_fn: 1645.0000 - val_accuracy: 0.9047 - val_precision: 0.8480 - val_recall: 0.8362 - val_auc: 0.9615 - val_f1_score: 0.8448 - val_average_precision: 0.8507\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2577 - tp: 19211.0000 - fp: 3237.0000 - tn: 50286.0000 - fn: 4375.0000 - accuracy: 0.9013 - precision: 0.8558 - recall: 0.8145 - auc: 0.9602 - f1_score: 0.8343 - average_precision: 0.8564 - val_loss: 0.2564 - val_tp: 7938.0000 - val_fp: 1061.0000 - val_tn: 21944.0000 - val_fn: 2104.0000 - val_accuracy: 0.9042 - val_precision: 0.8821 - val_recall: 0.7905 - val_auc: 0.9623 - val_f1_score: 0.8365 - val_average_precision: 0.8844\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 12s 324ms/step - loss: 0.2543 - tp: 19306.0000 - fp: 3103.0000 - tn: 50420.0000 - fn: 4280.0000 - accuracy: 0.9043 - precision: 0.8615 - recall: 0.8185 - auc: 0.9619 - f1_score: 0.8391 - average_precision: 0.8627 - val_loss: 0.2526 - val_tp: 8363.0000 - val_fp: 1403.0000 - val_tn: 21602.0000 - val_fn: 1679.0000 - val_accuracy: 0.9067 - val_precision: 0.8563 - val_recall: 0.8328 - val_auc: 0.9621 - val_f1_score: 0.8467 - val_average_precision: 0.8585\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2515 - tp: 19355.0000 - fp: 3094.0000 - tn: 50429.0000 - fn: 4231.0000 - accuracy: 0.9050 - precision: 0.8622 - recall: 0.8206 - auc: 0.9628 - f1_score: 0.8407 - average_precision: 0.8633 - val_loss: 0.2516 - val_tp: 8610.0000 - val_fp: 1695.0000 - val_tn: 21310.0000 - val_fn: 1432.0000 - val_accuracy: 0.9054 - val_precision: 0.8355 - val_recall: 0.8574 - val_auc: 0.9615 - val_f1_score: 0.8480 - val_average_precision: 0.8373\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 12s 324ms/step - loss: 0.2486 - tp: 19508.0000 - fp: 3114.0000 - tn: 50409.0000 - fn: 4078.0000 - accuracy: 0.9067 - precision: 0.8623 - recall: 0.8271 - auc: 0.9635 - f1_score: 0.8442 - average_precision: 0.8638 - val_loss: 0.2469 - val_tp: 8239.0000 - val_fp: 1159.0000 - val_tn: 21846.0000 - val_fn: 1803.0000 - val_accuracy: 0.9104 - val_precision: 0.8767 - val_recall: 0.8205 - val_auc: 0.9647 - val_f1_score: 0.8491 - val_average_precision: 0.8782\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2439 - tp: 19574.0000 - fp: 3011.0000 - tn: 50512.0000 - fn: 4012.0000 - accuracy: 0.9089 - precision: 0.8667 - recall: 0.8299 - auc: 0.9652 - f1_score: 0.8477 - average_precision: 0.8674 - val_loss: 0.2442 - val_tp: 8242.0000 - val_fp: 1147.0000 - val_tn: 21858.0000 - val_fn: 1800.0000 - val_accuracy: 0.9108 - val_precision: 0.8778 - val_recall: 0.8208 - val_auc: 0.9652 - val_f1_score: 0.8504 - val_average_precision: 0.8789\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2425 - tp: 19578.0000 - fp: 2936.0000 - tn: 50587.0000 - fn: 4008.0000 - accuracy: 0.9099 - precision: 0.8696 - recall: 0.8301 - auc: 0.9658 - f1_score: 0.8492 - average_precision: 0.8708 - val_loss: 0.2428 - val_tp: 8465.0000 - val_fp: 1282.0000 - val_tn: 21723.0000 - val_fn: 1577.0000 - val_accuracy: 0.9135 - val_precision: 0.8685 - val_recall: 0.8430 - val_auc: 0.9664 - val_f1_score: 0.8570 - val_average_precision: 0.8695\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2382 - tp: 19684.0000 - fp: 2841.0000 - tn: 50682.0000 - fn: 3902.0000 - accuracy: 0.9126 - precision: 0.8739 - recall: 0.8346 - auc: 0.9676 - f1_score: 0.8536 - average_precision: 0.8743 - val_loss: 0.2419 - val_tp: 7934.0000 - val_fp: 879.0000 - val_tn: 22126.0000 - val_fn: 2108.0000 - val_accuracy: 0.9096 - val_precision: 0.9003 - val_recall: 0.7901 - val_auc: 0.9659 - val_f1_score: 0.8443 - val_average_precision: 0.9028\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2352 - tp: 19750.0000 - fp: 2831.0000 - tn: 50692.0000 - fn: 3836.0000 - accuracy: 0.9135 - precision: 0.8746 - recall: 0.8374 - auc: 0.9682 - f1_score: 0.8553 - average_precision: 0.8753 - val_loss: 0.2365 - val_tp: 8335.0000 - val_fp: 1130.0000 - val_tn: 21875.0000 - val_fn: 1707.0000 - val_accuracy: 0.9142 - val_precision: 0.8806 - val_recall: 0.8300 - val_auc: 0.9679 - val_f1_score: 0.8566 - val_average_precision: 0.8821\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2324 - tp: 19782.0000 - fp: 2786.0000 - tn: 50737.0000 - fn: 3804.0000 - accuracy: 0.9145 - precision: 0.8766 - recall: 0.8387 - auc: 0.9690 - f1_score: 0.8570 - average_precision: 0.8772 - val_loss: 0.2374 - val_tp: 7910.0000 - val_fp: 773.0000 - val_tn: 22232.0000 - val_fn: 2132.0000 - val_accuracy: 0.9121 - val_precision: 0.9110 - val_recall: 0.7877 - val_auc: 0.9693 - val_f1_score: 0.8471 - val_average_precision: 0.9130\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2309 - tp: 19891.0000 - fp: 2755.0000 - tn: 50768.0000 - fn: 3695.0000 - accuracy: 0.9164 - precision: 0.8783 - recall: 0.8433 - auc: 0.9697 - f1_score: 0.8605 - average_precision: 0.8791 - val_loss: 0.2330 - val_tp: 8338.0000 - val_fp: 1025.0000 - val_tn: 21980.0000 - val_fn: 1704.0000 - val_accuracy: 0.9174 - val_precision: 0.8905 - val_recall: 0.8303 - val_auc: 0.9703 - val_f1_score: 0.8614 - val_average_precision: 0.8920\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2296 - tp: 19813.0000 - fp: 2725.0000 - tn: 50798.0000 - fn: 3773.0000 - accuracy: 0.9157 - precision: 0.8791 - recall: 0.8400 - auc: 0.9701 - f1_score: 0.8588 - average_precision: 0.8797 - val_loss: 0.2311 - val_tp: 8708.0000 - val_fp: 1429.0000 - val_tn: 21576.0000 - val_fn: 1334.0000 - val_accuracy: 0.9164 - val_precision: 0.8590 - val_recall: 0.8672 - val_auc: 0.9682 - val_f1_score: 0.8642 - val_average_precision: 0.8606\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2258 - tp: 19933.0000 - fp: 2620.0000 - tn: 50903.0000 - fn: 3653.0000 - accuracy: 0.9186 - precision: 0.8838 - recall: 0.8451 - auc: 0.9713 - f1_score: 0.8639 - average_precision: 0.8840 - val_loss: 0.2284 - val_tp: 8604.0000 - val_fp: 1258.0000 - val_tn: 21747.0000 - val_fn: 1438.0000 - val_accuracy: 0.9184 - val_precision: 0.8724 - val_recall: 0.8568 - val_auc: 0.9705 - val_f1_score: 0.8658 - val_average_precision: 0.8743\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2234 - tp: 19976.0000 - fp: 2617.0000 - tn: 50906.0000 - fn: 3610.0000 - accuracy: 0.9192 - precision: 0.8842 - recall: 0.8469 - auc: 0.9719 - f1_score: 0.8652 - average_precision: 0.8846 - val_loss: 0.2272 - val_tp: 8744.0000 - val_fp: 1353.0000 - val_tn: 21652.0000 - val_fn: 1298.0000 - val_accuracy: 0.9198 - val_precision: 0.8660 - val_recall: 0.8707 - val_auc: 0.9718 - val_f1_score: 0.8697 - val_average_precision: 0.8682\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2219 - tp: 20036.0000 - fp: 2579.0000 - tn: 50944.0000 - fn: 3550.0000 - accuracy: 0.9205 - precision: 0.8860 - recall: 0.8495 - auc: 0.9725 - f1_score: 0.8670 - average_precision: 0.8869 - val_loss: 0.2248 - val_tp: 8239.0000 - val_fp: 887.0000 - val_tn: 22118.0000 - val_fn: 1803.0000 - val_accuracy: 0.9186 - val_precision: 0.9028 - val_recall: 0.8205 - val_auc: 0.9715 - val_f1_score: 0.8618 - val_average_precision: 0.9047\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2197 - tp: 20029.0000 - fp: 2524.0000 - tn: 50999.0000 - fn: 3557.0000 - accuracy: 0.9211 - precision: 0.8881 - recall: 0.8492 - auc: 0.9732 - f1_score: 0.8682 - average_precision: 0.8894 - val_loss: 0.2226 - val_tp: 8401.0000 - val_fp: 988.0000 - val_tn: 22017.0000 - val_fn: 1641.0000 - val_accuracy: 0.9204 - val_precision: 0.8948 - val_recall: 0.8366 - val_auc: 0.9710 - val_f1_score: 0.8658 - val_average_precision: 0.8964\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2177 - tp: 20044.0000 - fp: 2475.0000 - tn: 51048.0000 - fn: 3542.0000 - accuracy: 0.9220 - precision: 0.8901 - recall: 0.8498 - auc: 0.9735 - f1_score: 0.8691 - average_precision: 0.8907 - val_loss: 0.2205 - val_tp: 8660.0000 - val_fp: 1222.0000 - val_tn: 21783.0000 - val_fn: 1382.0000 - val_accuracy: 0.9212 - val_precision: 0.8763 - val_recall: 0.8624 - val_auc: 0.9712 - val_f1_score: 0.8700 - val_average_precision: 0.8770\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2143 - tp: 20148.0000 - fp: 2408.0000 - tn: 51115.0000 - fn: 3438.0000 - accuracy: 0.9242 - precision: 0.8932 - recall: 0.8542 - auc: 0.9749 - f1_score: 0.8730 - average_precision: 0.8941 - val_loss: 0.2181 - val_tp: 8494.0000 - val_fp: 1083.0000 - val_tn: 21922.0000 - val_fn: 1548.0000 - val_accuracy: 0.9204 - val_precision: 0.8869 - val_recall: 0.8458 - val_auc: 0.9723 - val_f1_score: 0.8673 - val_average_precision: 0.8886\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2125 - tp: 20146.0000 - fp: 2432.0000 - tn: 51091.0000 - fn: 3440.0000 - accuracy: 0.9238 - precision: 0.8923 - recall: 0.8542 - auc: 0.9749 - f1_score: 0.8726 - average_precision: 0.8932 - val_loss: 0.2158 - val_tp: 8460.0000 - val_fp: 935.0000 - val_tn: 22070.0000 - val_fn: 1582.0000 - val_accuracy: 0.9238 - val_precision: 0.9005 - val_recall: 0.8425 - val_auc: 0.9744 - val_f1_score: 0.8719 - val_average_precision: 0.9025\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2101 - tp: 20228.0000 - fp: 2418.0000 - tn: 51105.0000 - fn: 3358.0000 - accuracy: 0.9251 - precision: 0.8932 - recall: 0.8576 - auc: 0.9758 - f1_score: 0.8750 - average_precision: 0.8936 - val_loss: 0.2163 - val_tp: 8289.0000 - val_fp: 873.0000 - val_tn: 22132.0000 - val_fn: 1753.0000 - val_accuracy: 0.9205 - val_precision: 0.9047 - val_recall: 0.8254 - val_auc: 0.9719 - val_f1_score: 0.8652 - val_average_precision: 0.9065\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2091 - tp: 20151.0000 - fp: 2303.0000 - tn: 51220.0000 - fn: 3435.0000 - accuracy: 0.9256 - precision: 0.8974 - recall: 0.8544 - auc: 0.9760 - f1_score: 0.8753 - average_precision: 0.8979 - val_loss: 0.2127 - val_tp: 8642.0000 - val_fp: 1091.0000 - val_tn: 21914.0000 - val_fn: 1400.0000 - val_accuracy: 0.9246 - val_precision: 0.8879 - val_recall: 0.8606 - val_auc: 0.9739 - val_f1_score: 0.8750 - val_average_precision: 0.8890\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 12s 321ms/step - loss: 0.2074 - tp: 20254.0000 - fp: 2364.0000 - tn: 51159.0000 - fn: 3332.0000 - accuracy: 0.9261 - precision: 0.8955 - recall: 0.8587 - auc: 0.9764 - f1_score: 0.8766 - average_precision: 0.8963 - val_loss: 0.2110 - val_tp: 8637.0000 - val_fp: 1046.0000 - val_tn: 21959.0000 - val_fn: 1405.0000 - val_accuracy: 0.9258 - val_precision: 0.8920 - val_recall: 0.8601 - val_auc: 0.9744 - val_f1_score: 0.8767 - val_average_precision: 0.8929\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2054 - tp: 20279.0000 - fp: 2359.0000 - tn: 51164.0000 - fn: 3307.0000 - accuracy: 0.9265 - precision: 0.8958 - recall: 0.8598 - auc: 0.9770 - f1_score: 0.8772 - average_precision: 0.8966 - val_loss: 0.2097 - val_tp: 8535.0000 - val_fp: 1033.0000 - val_tn: 21972.0000 - val_fn: 1507.0000 - val_accuracy: 0.9231 - val_precision: 0.8920 - val_recall: 0.8499 - val_auc: 0.9733 - val_f1_score: 0.8717 - val_average_precision: 0.8934\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.2038 - tp: 20296.0000 - fp: 2288.0000 - tn: 51235.0000 - fn: 3290.0000 - accuracy: 0.9277 - precision: 0.8987 - recall: 0.8605 - auc: 0.9771 - f1_score: 0.8790 - average_precision: 0.8995 - val_loss: 0.2073 - val_tp: 8659.0000 - val_fp: 954.0000 - val_tn: 22051.0000 - val_fn: 1383.0000 - val_accuracy: 0.9293 - val_precision: 0.9008 - val_recall: 0.8623 - val_auc: 0.9767 - val_f1_score: 0.8822 - val_average_precision: 0.9028\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.2009 - tp: 20342.0000 - fp: 2158.0000 - tn: 51365.0000 - fn: 3244.0000 - accuracy: 0.9299 - precision: 0.9041 - recall: 0.8625 - auc: 0.9781 - f1_score: 0.8826 - average_precision: 0.9045 - val_loss: 0.2062 - val_tp: 8508.0000 - val_fp: 888.0000 - val_tn: 22117.0000 - val_fn: 1534.0000 - val_accuracy: 0.9267 - val_precision: 0.9055 - val_recall: 0.8472 - val_auc: 0.9757 - val_f1_score: 0.8768 - val_average_precision: 0.9073\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.1997 - tp: 20399.0000 - fp: 2149.0000 - tn: 51374.0000 - fn: 3187.0000 - accuracy: 0.9308 - precision: 0.9047 - recall: 0.8649 - auc: 0.9785 - f1_score: 0.8842 - average_precision: 0.9049 - val_loss: 0.2068 - val_tp: 8505.0000 - val_fp: 1014.0000 - val_tn: 21991.0000 - val_fn: 1537.0000 - val_accuracy: 0.9228 - val_precision: 0.8935 - val_recall: 0.8469 - val_auc: 0.9729 - val_f1_score: 0.8712 - val_average_precision: 0.8958\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.1975 - tp: 20359.0000 - fp: 2131.0000 - tn: 51392.0000 - fn: 3227.0000 - accuracy: 0.9305 - precision: 0.9052 - recall: 0.8632 - auc: 0.9788 - f1_score: 0.8836 - average_precision: 0.9056 - val_loss: 0.2036 - val_tp: 8660.0000 - val_fp: 1046.0000 - val_tn: 21959.0000 - val_fn: 1382.0000 - val_accuracy: 0.9265 - val_precision: 0.8922 - val_recall: 0.8624 - val_auc: 0.9755 - val_f1_score: 0.8784 - val_average_precision: 0.8947\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.1962 - tp: 20396.0000 - fp: 2107.0000 - tn: 51416.0000 - fn: 3190.0000 - accuracy: 0.9313 - precision: 0.9064 - recall: 0.8648 - auc: 0.9791 - f1_score: 0.8848 - average_precision: 0.9067 - val_loss: 0.2031 - val_tp: 8901.0000 - val_fp: 1222.0000 - val_tn: 21783.0000 - val_fn: 1141.0000 - val_accuracy: 0.9285 - val_precision: 0.8793 - val_recall: 0.8864 - val_auc: 0.9769 - val_f1_score: 0.8837 - val_average_precision: 0.8809\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.1941 - tp: 20484.0000 - fp: 2060.0000 - tn: 51463.0000 - fn: 3102.0000 - accuracy: 0.9331 - precision: 0.9086 - recall: 0.8685 - auc: 0.9797 - f1_score: 0.8880 - average_precision: 0.9092 - val_loss: 0.2002 - val_tp: 8547.0000 - val_fp: 877.0000 - val_tn: 22128.0000 - val_fn: 1495.0000 - val_accuracy: 0.9282 - val_precision: 0.9069 - val_recall: 0.8511 - val_auc: 0.9770 - val_f1_score: 0.8789 - val_average_precision: 0.9081\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1925 - tp: 20434.0000 - fp: 2042.0000 - tn: 51481.0000 - fn: 3152.0000 - accuracy: 0.9326 - precision: 0.9091 - recall: 0.8664 - auc: 0.9798 - f1_score: 0.8872 - average_precision: 0.9095Restoring model weights from the end of the best epoch.\n",
      "38/38 [==============================] - 12s 322ms/step - loss: 0.1925 - tp: 20434.0000 - fp: 2042.0000 - tn: 51481.0000 - fn: 3152.0000 - accuracy: 0.9326 - precision: 0.9091 - recall: 0.8664 - auc: 0.9798 - f1_score: 0.8872 - average_precision: 0.9095 - val_loss: 0.2001 - val_tp: 8815.0000 - val_fp: 997.0000 - val_tn: 22008.0000 - val_fn: 1227.0000 - val_accuracy: 0.9327 - val_precision: 0.8984 - val_recall: 0.8778 - val_auc: 0.9794 - val_f1_score: 0.8891 - val_average_precision: 0.9006\n",
      "Epoch 00056: early stopping\n"
     ]
    }
   ],
   "source": [
    "# # Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_average_precision', \n",
    "    verbose=1,\n",
    "    patience=20,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "history = model.fit({'main_input': train_sequence_data, 'aux_input': train_unsupervised_data},\n",
    "          {'main_output': train_labels},\n",
    "          epochs=200,validation_split=0.3,\n",
    "#           validation_data=([val_features_sequence,val_features_unsupervised],val_labels),\n",
    "          batch_size=2048, verbose=1, callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss',\n",
       " 'tp',\n",
       " 'fp',\n",
       " 'tn',\n",
       " 'fn',\n",
       " 'accuracy',\n",
       " 'precision',\n",
       " 'recall',\n",
       " 'auc',\n",
       " 'f1_score',\n",
       " 'average_precision']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20011594891548157\n",
      "8815.0\n",
      "997.0\n",
      "22008.0\n",
      "1227.0\n",
      "0.9327018857002258\n",
      "0.8983896970748901\n",
      "0.8778131604194641\n",
      "0.9793612360954285\n",
      "0.8890920877456665\n",
      "0.900587260723114\n"
     ]
    }
   ],
   "source": [
    "print(history.history['val_loss'][55])\n",
    "print(history.history['val_tp'][55])\n",
    "print(history.history['val_fp'][55])\n",
    "print(history.history['val_tn'][55])\n",
    "print(history.history['val_fn'][55])\n",
    "print(history.history['val_accuracy'][55])\n",
    "print(history.history['val_precision'][55])\n",
    "print(history.history['val_recall'][55])\n",
    "print(history.history['val_auc'][55])\n",
    "print(history.history['val_f1_score'][55])\n",
    "print(history.history['val_average_precision'][55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 73ms/step - loss: 0.2945 - tp: 2641.0000 - fp: 598.0000 - tn: 5940.0000 - fn: 628.0000 - accuracy: 0.8750 - precision: 0.8154 - recall: 0.8079 - auc: 0.9448 - f1_score: 0.8117 - average_precision: 0.8155\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on test data\n",
    "results = model.evaluate([test_sequence_data,test_unsupervised_data],\n",
    "                         test_labels, batch_size=2048, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss',\n",
       " 'tp',\n",
       " 'fp',\n",
       " 'tn',\n",
       " 'fn',\n",
       " 'accuracy',\n",
       " 'precision',\n",
       " 'recall',\n",
       " 'auc',\n",
       " 'f1_score',\n",
       " 'average_precision']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2944844961166382, 2641.0, 598.0, 5940.0, 628.0, 0.8749872446060181, 0.8153750896453857, 0.8078923225402832, 0.9447919726371765, 0.8117319345474243, 0.8154597282409668]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09315826]\n",
      " [0.01751389]\n",
      " [0.7259559 ]\n",
      " ...\n",
      " [0.4219809 ]\n",
      " [0.7186493 ]\n",
      " [0.06293106]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting probability of different output classes\n",
    "\n",
    "predicted_proba = model.predict({'main_input': test_sequence_data, 'aux_input': test_unsupervised_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test_labels).reshape(9807,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = np.append(predicted_proba, np.array(test_labels).reshape(9807,1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = pd.DataFrame(columns = ['probability','classes'],data = y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df.to_csv('/home/boses08/hype-prediction-longitudinal/ml/v2/src/Suparno Experiment/Class_prediction_probability_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "result of model.predict_proba --> test_class\n",
    "\n",
    "only main input with LSTM\n",
    "\n",
    "only aux data with LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating the LSTM model with only sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_template import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "em_1 (Embedding)             (None, 150, 100)          34100     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150, 100)          80400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 195,001\n",
      "Trainable params: 195,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model = make_model(Config.VOCAB_SIZE,\n",
    "#                    Config.EMBEDDING_DIM,\n",
    "#                    Config.MAX_REVIEW_LENGTH,\n",
    "#                    Config.METRICS)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        Config.VOCAB_SIZE, Config.EMBEDDING_DIM, input_length=Config.MAX_REVIEW_LENGTH, name=\"em_1\"\n",
    "    )\n",
    ")\n",
    "model.add(tf.keras.layers.LSTM(100, name=\"lstm_1\", dropout=0.5, return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(100, name=\"lstm_2\"))\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        1, activation=\"sigmoid\", name=\"output\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=Config.METRICS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/only_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "38/38 [==============================] - 23s 595ms/step - loss: 0.5365 - tp: 9025.0000 - fp: 5847.0000 - tn: 54214.0000 - fn: 17830.0000 - accuracy: 0.7276 - precision: 0.6068 - recall: 0.3361 - auc: 0.7449 - f1_score: 0.3494 - average_precision: 0.4560 - val_loss: 0.4720 - val_tp: 5700.0000 - val_fp: 3408.0000 - val_tn: 19597.0000 - val_fn: 4342.0000 - val_accuracy: 0.7655 - val_precision: 0.6258 - val_recall: 0.5676 - val_auc: 0.8169 - val_f1_score: 0.5990 - val_average_precision: 0.6303\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 21s 558ms/step - loss: 0.4665 - tp: 12870.0000 - fp: 6911.0000 - tn: 46612.0000 - fn: 10716.0000 - accuracy: 0.7714 - precision: 0.6506 - recall: 0.5457 - auc: 0.8223 - f1_score: 0.5925 - average_precision: 0.6514 - val_loss: 0.4531 - val_tp: 5872.0000 - val_fp: 3016.0000 - val_tn: 19989.0000 - val_fn: 4170.0000 - val_accuracy: 0.7826 - val_precision: 0.6607 - val_recall: 0.5847 - val_auc: 0.8344 - val_f1_score: 0.6254 - val_average_precision: 0.6686\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 21s 557ms/step - loss: 0.4558 - tp: 14066.0000 - fp: 7521.0000 - tn: 46002.0000 - fn: 9520.0000 - accuracy: 0.7790 - precision: 0.6516 - recall: 0.5964 - auc: 0.8322 - f1_score: 0.6221 - average_precision: 0.6518 - val_loss: 0.4496 - val_tp: 5500.0000 - val_fp: 2552.0000 - val_tn: 20453.0000 - val_fn: 4542.0000 - val_accuracy: 0.7853 - val_precision: 0.6831 - val_recall: 0.5477 - val_auc: 0.8384 - val_f1_score: 0.6114 - val_average_precision: 0.6896\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 21s 556ms/step - loss: 0.4513 - tp: 13934.0000 - fp: 7277.0000 - tn: 46246.0000 - fn: 9652.0000 - accuracy: 0.7805 - precision: 0.6569 - recall: 0.5908 - auc: 0.8362 - f1_score: 0.6215 - average_precision: 0.6572 - val_loss: 0.4442 - val_tp: 6097.0000 - val_fp: 3154.0000 - val_tn: 19851.0000 - val_fn: 3945.0000 - val_accuracy: 0.7852 - val_precision: 0.6591 - val_recall: 0.6071 - val_auc: 0.8422 - val_f1_score: 0.6368 - val_average_precision: 0.6663\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 21s 557ms/step - loss: 0.4497 - tp: 14130.0000 - fp: 7382.0000 - tn: 46141.0000 - fn: 9456.0000 - accuracy: 0.7816 - precision: 0.6568 - recall: 0.5991 - auc: 0.8375 - f1_score: 0.6266 - average_precision: 0.6575 - val_loss: 0.4476 - val_tp: 6410.0000 - val_fp: 3589.0000 - val_tn: 19416.0000 - val_fn: 3632.0000 - val_accuracy: 0.7815 - val_precision: 0.6411 - val_recall: 0.6383 - val_auc: 0.8416 - val_f1_score: 0.6430 - val_average_precision: 0.6475\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 21s 557ms/step - loss: 0.4467 - tp: 14250.0000 - fp: 7398.0000 - tn: 46125.0000 - fn: 9336.0000 - accuracy: 0.7830 - precision: 0.6583 - recall: 0.6042 - auc: 0.8401 - f1_score: 0.6296 - average_precision: 0.6591 - val_loss: 0.4410 - val_tp: 6077.0000 - val_fp: 3151.0000 - val_tn: 19854.0000 - val_fn: 3965.0000 - val_accuracy: 0.7847 - val_precision: 0.6585 - val_recall: 0.6052 - val_auc: 0.8441 - val_f1_score: 0.6343 - val_average_precision: 0.6653\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 21s 556ms/step - loss: 0.4445 - tp: 13857.0000 - fp: 7026.0000 - tn: 46497.0000 - fn: 9729.0000 - accuracy: 0.7827 - precision: 0.6636 - recall: 0.5875 - auc: 0.8418 - f1_score: 0.6230 - average_precision: 0.6650 - val_loss: 0.4417 - val_tp: 6463.0000 - val_fp: 3628.0000 - val_tn: 19377.0000 - val_fn: 3579.0000 - val_accuracy: 0.7819 - val_precision: 0.6405 - val_recall: 0.6436 - val_auc: 0.8446 - val_f1_score: 0.6466 - val_average_precision: 0.6478\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 21s 557ms/step - loss: 0.4428 - tp: 14074.0000 - fp: 7062.0000 - tn: 46461.0000 - fn: 9512.0000 - accuracy: 0.7851 - precision: 0.6659 - recall: 0.5967 - auc: 0.8430 - f1_score: 0.6280 - average_precision: 0.6675 - val_loss: 0.4444 - val_tp: 5234.0000 - val_fp: 2313.0000 - val_tn: 20692.0000 - val_fn: 4808.0000 - val_accuracy: 0.7845 - val_precision: 0.6935 - val_recall: 0.5212 - val_auc: 0.8450 - val_f1_score: 0.5974 - val_average_precision: 0.7000\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 21s 556ms/step - loss: 0.4398 - tp: 13959.0000 - fp: 6777.0000 - tn: 46746.0000 - fn: 9627.0000 - accuracy: 0.7873 - precision: 0.6732 - recall: 0.5918 - auc: 0.8455 - f1_score: 0.6285 - average_precision: 0.6748 - val_loss: 0.4366 - val_tp: 5894.0000 - val_fp: 2891.0000 - val_tn: 20114.0000 - val_fn: 4148.0000 - val_accuracy: 0.7870 - val_precision: 0.6709 - val_recall: 0.5869 - val_auc: 0.8473 - val_f1_score: 0.6301 - val_average_precision: 0.6781\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4381 - tp: 14076.0000 - fp: 6864.0000 - tn: 46659.0000 - fn: 9510.0000 - accuracy: 0.7877 - precision: 0.6722 - recall: 0.5968 - auc: 0.8468 - f1_score: 0.6322 - average_precision: 0.6730 - val_loss: 0.4366 - val_tp: 6283.0000 - val_fp: 3315.0000 - val_tn: 19690.0000 - val_fn: 3759.0000 - val_accuracy: 0.7859 - val_precision: 0.6546 - val_recall: 0.6257 - val_auc: 0.8482 - val_f1_score: 0.6435 - val_average_precision: 0.6604\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.4380 - tp: 14169.0000 - fp: 6947.0000 - tn: 46576.0000 - fn: 9417.0000 - accuracy: 0.7878 - precision: 0.6710 - recall: 0.6007 - auc: 0.8469 - f1_score: 0.6335 - average_precision: 0.6723 - val_loss: 0.4391 - val_tp: 5484.0000 - val_fp: 2511.0000 - val_tn: 20494.0000 - val_fn: 4558.0000 - val_accuracy: 0.7861 - val_precision: 0.6859 - val_recall: 0.5461 - val_auc: 0.8460 - val_f1_score: 0.6125 - val_average_precision: 0.6921\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 21s 559ms/step - loss: 0.4369 - tp: 14106.0000 - fp: 6818.0000 - tn: 46705.0000 - fn: 9480.0000 - accuracy: 0.7886 - precision: 0.6742 - recall: 0.5981 - auc: 0.8477 - f1_score: 0.6330 - average_precision: 0.6751 - val_loss: 0.4401 - val_tp: 6593.0000 - val_fp: 3737.0000 - val_tn: 19268.0000 - val_fn: 3449.0000 - val_accuracy: 0.7826 - val_precision: 0.6382 - val_recall: 0.6565 - val_auc: 0.8461 - val_f1_score: 0.6518 - val_average_precision: 0.6456\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 21s 557ms/step - loss: 0.4352 - tp: 14083.0000 - fp: 6806.0000 - tn: 46717.0000 - fn: 9503.0000 - accuracy: 0.7885 - precision: 0.6742 - recall: 0.5971 - auc: 0.8489 - f1_score: 0.6319 - average_precision: 0.6758 - val_loss: 0.4339 - val_tp: 6173.0000 - val_fp: 3062.0000 - val_tn: 19943.0000 - val_fn: 3869.0000 - val_accuracy: 0.7903 - val_precision: 0.6684 - val_recall: 0.6147 - val_auc: 0.8508 - val_f1_score: 0.6448 - val_average_precision: 0.6760\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4336 - tp: 14049.0000 - fp: 6579.0000 - tn: 46944.0000 - fn: 9537.0000 - accuracy: 0.7910 - precision: 0.6811 - recall: 0.5956 - auc: 0.8504 - f1_score: 0.6352 - average_precision: 0.6815 - val_loss: 0.4404 - val_tp: 5844.0000 - val_fp: 2805.0000 - val_tn: 20200.0000 - val_fn: 4198.0000 - val_accuracy: 0.7881 - val_precision: 0.6757 - val_recall: 0.5820 - val_auc: 0.8440 - val_f1_score: 0.6285 - val_average_precision: 0.6812\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4350 - tp: 14019.0000 - fp: 6617.0000 - tn: 46906.0000 - fn: 9567.0000 - accuracy: 0.7901 - precision: 0.6793 - recall: 0.5944 - auc: 0.8492 - f1_score: 0.6332 - average_precision: 0.6815 - val_loss: 0.4306 - val_tp: 5742.0000 - val_fp: 2594.0000 - val_tn: 20411.0000 - val_fn: 4300.0000 - val_accuracy: 0.7914 - val_precision: 0.6888 - val_recall: 0.5718 - val_auc: 0.8522 - val_f1_score: 0.6278 - val_average_precision: 0.6951\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4333 - tp: 13961.0000 - fp: 6477.0000 - tn: 47046.0000 - fn: 9625.0000 - accuracy: 0.7912 - precision: 0.6831 - recall: 0.5919 - auc: 0.8506 - f1_score: 0.6341 - average_precision: 0.6837 - val_loss: 0.4345 - val_tp: 6069.0000 - val_fp: 2877.0000 - val_tn: 20128.0000 - val_fn: 3973.0000 - val_accuracy: 0.7927 - val_precision: 0.6784 - val_recall: 0.6044 - val_auc: 0.8512 - val_f1_score: 0.6430 - val_average_precision: 0.6857\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 21s 559ms/step - loss: 0.4325 - tp: 14196.0000 - fp: 6682.0000 - tn: 46841.0000 - fn: 9390.0000 - accuracy: 0.7916 - precision: 0.6800 - recall: 0.6019 - auc: 0.8511 - f1_score: 0.6382 - average_precision: 0.6811 - val_loss: 0.4316 - val_tp: 5977.0000 - val_fp: 2782.0000 - val_tn: 20223.0000 - val_fn: 4065.0000 - val_accuracy: 0.7928 - val_precision: 0.6824 - val_recall: 0.5952 - val_auc: 0.8521 - val_f1_score: 0.6391 - val_average_precision: 0.6893\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4314 - tp: 14153.0000 - fp: 6487.0000 - tn: 47036.0000 - fn: 9433.0000 - accuracy: 0.7935 - precision: 0.6857 - recall: 0.6001 - auc: 0.8521 - f1_score: 0.6395 - average_precision: 0.6864 - val_loss: 0.4292 - val_tp: 6213.0000 - val_fp: 3011.0000 - val_tn: 19994.0000 - val_fn: 3829.0000 - val_accuracy: 0.7930 - val_precision: 0.6736 - val_recall: 0.6187 - val_auc: 0.8536 - val_f1_score: 0.6487 - val_average_precision: 0.6806\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4298 - tp: 14271.0000 - fp: 6599.0000 - tn: 46924.0000 - fn: 9315.0000 - accuracy: 0.7936 - precision: 0.6838 - recall: 0.6051 - auc: 0.8533 - f1_score: 0.6417 - average_precision: 0.6844 - val_loss: 0.4312 - val_tp: 6077.0000 - val_fp: 3014.0000 - val_tn: 19991.0000 - val_fn: 3965.0000 - val_accuracy: 0.7888 - val_precision: 0.6685 - val_recall: 0.6052 - val_auc: 0.8515 - val_f1_score: 0.6388 - val_average_precision: 0.6751\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4294 - tp: 14418.0000 - fp: 6726.0000 - tn: 46797.0000 - fn: 9168.0000 - accuracy: 0.7939 - precision: 0.6819 - recall: 0.6113 - auc: 0.8535 - f1_score: 0.6443 - average_precision: 0.6823 - val_loss: 0.4387 - val_tp: 5705.0000 - val_fp: 2558.0000 - val_tn: 20447.0000 - val_fn: 4337.0000 - val_accuracy: 0.7914 - val_precision: 0.6904 - val_recall: 0.5681 - val_auc: 0.8478 - val_f1_score: 0.6265 - val_average_precision: 0.6966\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4316 - tp: 14321.0000 - fp: 6810.0000 - tn: 46713.0000 - fn: 9265.0000 - accuracy: 0.7915 - precision: 0.6777 - recall: 0.6072 - auc: 0.8520 - f1_score: 0.6399 - average_precision: 0.6789 - val_loss: 0.4295 - val_tp: 5898.0000 - val_fp: 2800.0000 - val_tn: 20205.0000 - val_fn: 4144.0000 - val_accuracy: 0.7899 - val_precision: 0.6781 - val_recall: 0.5873 - val_auc: 0.8532 - val_f1_score: 0.6328 - val_average_precision: 0.6845\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4274 - tp: 14210.0000 - fp: 6480.0000 - tn: 47043.0000 - fn: 9376.0000 - accuracy: 0.7944 - precision: 0.6868 - recall: 0.6025 - auc: 0.8551 - f1_score: 0.6410 - average_precision: 0.6880 - val_loss: 0.4279 - val_tp: 6600.0000 - val_fp: 3479.0000 - val_tn: 19526.0000 - val_fn: 3442.0000 - val_accuracy: 0.7906 - val_precision: 0.6548 - val_recall: 0.6572 - val_auc: 0.8549 - val_f1_score: 0.6601 - val_average_precision: 0.6617\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.4241 - tp: 14463.0000 - fp: 6643.0000 - tn: 46880.0000 - fn: 9123.0000 - accuracy: 0.7955 - precision: 0.6853 - recall: 0.6132 - auc: 0.8574 - f1_score: 0.6465 - average_precision: 0.6857 - val_loss: 0.4235 - val_tp: 6314.0000 - val_fp: 3078.0000 - val_tn: 19927.0000 - val_fn: 3728.0000 - val_accuracy: 0.7941 - val_precision: 0.6723 - val_recall: 0.6288 - val_auc: 0.8575 - val_f1_score: 0.6535 - val_average_precision: 0.6790\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4252 - tp: 14532.0000 - fp: 6810.0000 - tn: 46713.0000 - fn: 9054.0000 - accuracy: 0.7943 - precision: 0.6809 - recall: 0.6161 - auc: 0.8566 - f1_score: 0.6471 - average_precision: 0.6830 - val_loss: 0.4257 - val_tp: 5556.0000 - val_fp: 2388.0000 - val_tn: 20617.0000 - val_fn: 4486.0000 - val_accuracy: 0.7920 - val_precision: 0.6994 - val_recall: 0.5533 - val_auc: 0.8568 - val_f1_score: 0.6220 - val_average_precision: 0.7053\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4224 - tp: 14212.0000 - fp: 6277.0000 - tn: 47246.0000 - fn: 9374.0000 - accuracy: 0.7970 - precision: 0.6936 - recall: 0.6026 - auc: 0.8589 - f1_score: 0.6444 - average_precision: 0.6944 - val_loss: 0.4242 - val_tp: 6296.0000 - val_fp: 3039.0000 - val_tn: 19966.0000 - val_fn: 3746.0000 - val_accuracy: 0.7947 - val_precision: 0.6745 - val_recall: 0.6270 - val_auc: 0.8574 - val_f1_score: 0.6546 - val_average_precision: 0.6814\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4201 - tp: 14337.0000 - fp: 6424.0000 - tn: 47099.0000 - fn: 9249.0000 - accuracy: 0.7967 - precision: 0.6906 - recall: 0.6079 - auc: 0.8605 - f1_score: 0.6463 - average_precision: 0.6915 - val_loss: 0.4219 - val_tp: 6018.0000 - val_fp: 2727.0000 - val_tn: 20278.0000 - val_fn: 4024.0000 - val_accuracy: 0.7957 - val_precision: 0.6882 - val_recall: 0.5993 - val_auc: 0.8586 - val_f1_score: 0.6456 - val_average_precision: 0.6963\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4220 - tp: 14533.0000 - fp: 6625.0000 - tn: 46898.0000 - fn: 9053.0000 - accuracy: 0.7967 - precision: 0.6869 - recall: 0.6162 - auc: 0.8589 - f1_score: 0.6493 - average_precision: 0.6879 - val_loss: 0.4249 - val_tp: 6223.0000 - val_fp: 3005.0000 - val_tn: 20000.0000 - val_fn: 3819.0000 - val_accuracy: 0.7935 - val_precision: 0.6744 - val_recall: 0.6197 - val_auc: 0.8569 - val_f1_score: 0.6508 - val_average_precision: 0.6827\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 21s 559ms/step - loss: 0.4218 - tp: 14255.0000 - fp: 6290.0000 - tn: 47233.0000 - fn: 9331.0000 - accuracy: 0.7974 - precision: 0.6938 - recall: 0.6044 - auc: 0.8592 - f1_score: 0.6453 - average_precision: 0.6941 - val_loss: 0.4247 - val_tp: 5927.0000 - val_fp: 2719.0000 - val_tn: 20286.0000 - val_fn: 4115.0000 - val_accuracy: 0.7932 - val_precision: 0.6855 - val_recall: 0.5902 - val_auc: 0.8572 - val_f1_score: 0.6378 - val_average_precision: 0.6916\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4242 - tp: 14276.0000 - fp: 6349.0000 - tn: 47174.0000 - fn: 9310.0000 - accuracy: 0.7969 - precision: 0.6922 - recall: 0.6053 - auc: 0.8574 - f1_score: 0.6457 - average_precision: 0.6929 - val_loss: 0.4281 - val_tp: 6730.0000 - val_fp: 3561.0000 - val_tn: 19444.0000 - val_fn: 3312.0000 - val_accuracy: 0.7920 - val_precision: 0.6540 - val_recall: 0.6702 - val_auc: 0.8558 - val_f1_score: 0.6660 - val_average_precision: 0.6602\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4200 - tp: 14183.0000 - fp: 6233.0000 - tn: 47290.0000 - fn: 9403.0000 - accuracy: 0.7972 - precision: 0.6947 - recall: 0.6013 - auc: 0.8604 - f1_score: 0.6443 - average_precision: 0.6958 - val_loss: 0.4229 - val_tp: 6213.0000 - val_fp: 2952.0000 - val_tn: 20053.0000 - val_fn: 3829.0000 - val_accuracy: 0.7948 - val_precision: 0.6779 - val_recall: 0.6187 - val_auc: 0.8579 - val_f1_score: 0.6514 - val_average_precision: 0.6850\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4191 - tp: 14355.0000 - fp: 6376.0000 - tn: 47147.0000 - fn: 9231.0000 - accuracy: 0.7976 - precision: 0.6924 - recall: 0.6086 - auc: 0.8611 - f1_score: 0.6469 - average_precision: 0.6939 - val_loss: 0.4213 - val_tp: 5906.0000 - val_fp: 2617.0000 - val_tn: 20388.0000 - val_fn: 4136.0000 - val_accuracy: 0.7957 - val_precision: 0.6929 - val_recall: 0.5881 - val_auc: 0.8590 - val_f1_score: 0.6409 - val_average_precision: 0.6987\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4181 - tp: 14318.0000 - fp: 6205.0000 - tn: 47318.0000 - fn: 9268.0000 - accuracy: 0.7993 - precision: 0.6977 - recall: 0.6071 - auc: 0.8620 - f1_score: 0.6488 - average_precision: 0.6985 - val_loss: 0.4217 - val_tp: 6106.0000 - val_fp: 2817.0000 - val_tn: 20188.0000 - val_fn: 3936.0000 - val_accuracy: 0.7957 - val_precision: 0.6843 - val_recall: 0.6080 - val_auc: 0.8588 - val_f1_score: 0.6492 - val_average_precision: 0.6912\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 21s 557ms/step - loss: 0.4185 - tp: 14405.0000 - fp: 6384.0000 - tn: 47139.0000 - fn: 9181.0000 - accuracy: 0.7981 - precision: 0.6929 - recall: 0.6107 - auc: 0.8616 - f1_score: 0.6492 - average_precision: 0.6938 - val_loss: 0.4210 - val_tp: 5840.0000 - val_fp: 2582.0000 - val_tn: 20423.0000 - val_fn: 4202.0000 - val_accuracy: 0.7947 - val_precision: 0.6934 - val_recall: 0.5816 - val_auc: 0.8590 - val_f1_score: 0.6359 - val_average_precision: 0.6996\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4167 - tp: 14435.0000 - fp: 6194.0000 - tn: 47329.0000 - fn: 9151.0000 - accuracy: 0.8010 - precision: 0.6997 - recall: 0.6120 - auc: 0.8632 - f1_score: 0.6525 - average_precision: 0.7009 - val_loss: 0.4225 - val_tp: 6099.0000 - val_fp: 2749.0000 - val_tn: 20256.0000 - val_fn: 3943.0000 - val_accuracy: 0.7975 - val_precision: 0.6893 - val_recall: 0.6073 - val_auc: 0.8586 - val_f1_score: 0.6508 - val_average_precision: 0.6964\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4176 - tp: 14407.0000 - fp: 6240.0000 - tn: 47283.0000 - fn: 9179.0000 - accuracy: 0.8000 - precision: 0.6978 - recall: 0.6108 - auc: 0.8623 - f1_score: 0.6508 - average_precision: 0.7003 - val_loss: 0.4208 - val_tp: 6203.0000 - val_fp: 2854.0000 - val_tn: 20151.0000 - val_fn: 3839.0000 - val_accuracy: 0.7975 - val_precision: 0.6849 - val_recall: 0.6177 - val_auc: 0.8594 - val_f1_score: 0.6550 - val_average_precision: 0.6920\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4141 - tp: 14696.0000 - fp: 6416.0000 - tn: 47107.0000 - fn: 8890.0000 - accuracy: 0.8015 - precision: 0.6961 - recall: 0.6231 - auc: 0.8650 - f1_score: 0.6568 - average_precision: 0.6962 - val_loss: 0.4230 - val_tp: 5444.0000 - val_fp: 2178.0000 - val_tn: 20827.0000 - val_fn: 4598.0000 - val_accuracy: 0.7950 - val_precision: 0.7142 - val_recall: 0.5421 - val_auc: 0.8590 - val_f1_score: 0.6210 - val_average_precision: 0.7224\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4152 - tp: 14375.0000 - fp: 6160.0000 - tn: 47363.0000 - fn: 9211.0000 - accuracy: 0.8007 - precision: 0.7000 - recall: 0.6095 - auc: 0.8640 - f1_score: 0.6505 - average_precision: 0.7017 - val_loss: 0.4194 - val_tp: 5996.0000 - val_fp: 2667.0000 - val_tn: 20338.0000 - val_fn: 4046.0000 - val_accuracy: 0.7969 - val_precision: 0.6921 - val_recall: 0.5971 - val_auc: 0.8602 - val_f1_score: 0.6451 - val_average_precision: 0.6994\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4133 - tp: 14391.0000 - fp: 6138.0000 - tn: 47385.0000 - fn: 9195.0000 - accuracy: 0.8012 - precision: 0.7010 - recall: 0.6102 - auc: 0.8654 - f1_score: 0.6515 - average_precision: 0.7023 - val_loss: 0.4218 - val_tp: 5470.0000 - val_fp: 2217.0000 - val_tn: 20788.0000 - val_fn: 4572.0000 - val_accuracy: 0.7946 - val_precision: 0.7116 - val_recall: 0.5447 - val_auc: 0.8591 - val_f1_score: 0.6222 - val_average_precision: 0.7181\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4135 - tp: 14408.0000 - fp: 6241.0000 - tn: 47282.0000 - fn: 9178.0000 - accuracy: 0.8000 - precision: 0.6978 - recall: 0.6109 - auc: 0.8651 - f1_score: 0.6505 - average_precision: 0.6989 - val_loss: 0.4184 - val_tp: 6461.0000 - val_fp: 3083.0000 - val_tn: 19922.0000 - val_fn: 3581.0000 - val_accuracy: 0.7983 - val_precision: 0.6770 - val_recall: 0.6434 - val_auc: 0.8617 - val_f1_score: 0.6648 - val_average_precision: 0.6849\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 21s 559ms/step - loss: 0.4118 - tp: 14583.0000 - fp: 6249.0000 - tn: 47274.0000 - fn: 9003.0000 - accuracy: 0.8022 - precision: 0.7000 - recall: 0.6183 - auc: 0.8664 - f1_score: 0.6560 - average_precision: 0.7018 - val_loss: 0.4197 - val_tp: 6275.0000 - val_fp: 2931.0000 - val_tn: 20074.0000 - val_fn: 3767.0000 - val_accuracy: 0.7973 - val_precision: 0.6816 - val_recall: 0.6249 - val_auc: 0.8610 - val_f1_score: 0.6566 - val_average_precision: 0.6886\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4100 - tp: 14650.0000 - fp: 6289.0000 - tn: 47234.0000 - fn: 8936.0000 - accuracy: 0.8026 - precision: 0.6997 - recall: 0.6211 - auc: 0.8678 - f1_score: 0.6573 - average_precision: 0.7018 - val_loss: 0.4190 - val_tp: 6071.0000 - val_fp: 2713.0000 - val_tn: 20292.0000 - val_fn: 3971.0000 - val_accuracy: 0.7977 - val_precision: 0.6911 - val_recall: 0.6046 - val_auc: 0.8608 - val_f1_score: 0.6505 - val_average_precision: 0.6994\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4100 - tp: 14721.0000 - fp: 6249.0000 - tn: 47274.0000 - fn: 8865.0000 - accuracy: 0.8040 - precision: 0.7020 - recall: 0.6241 - auc: 0.8679 - f1_score: 0.6605 - average_precision: 0.7036 - val_loss: 0.4194 - val_tp: 5976.0000 - val_fp: 2637.0000 - val_tn: 20368.0000 - val_fn: 4066.0000 - val_accuracy: 0.7972 - val_precision: 0.6938 - val_recall: 0.5951 - val_auc: 0.8614 - val_f1_score: 0.6459 - val_average_precision: 0.7012\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4081 - tp: 14578.0000 - fp: 6184.0000 - tn: 47339.0000 - fn: 9008.0000 - accuracy: 0.8030 - precision: 0.7021 - recall: 0.6181 - auc: 0.8691 - f1_score: 0.6567 - average_precision: 0.7030 - val_loss: 0.4174 - val_tp: 6046.0000 - val_fp: 2678.0000 - val_tn: 20327.0000 - val_fn: 3996.0000 - val_accuracy: 0.7980 - val_precision: 0.6930 - val_recall: 0.6021 - val_auc: 0.8621 - val_f1_score: 0.6494 - val_average_precision: 0.7015\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4081 - tp: 14849.0000 - fp: 6346.0000 - tn: 47177.0000 - fn: 8737.0000 - accuracy: 0.8044 - precision: 0.7006 - recall: 0.6296 - auc: 0.8690 - f1_score: 0.6621 - average_precision: 0.7016 - val_loss: 0.4205 - val_tp: 5530.0000 - val_fp: 2203.0000 - val_tn: 20802.0000 - val_fn: 4512.0000 - val_accuracy: 0.7968 - val_precision: 0.7151 - val_recall: 0.5507 - val_auc: 0.8611 - val_f1_score: 0.6264 - val_average_precision: 0.7219\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 21s 557ms/step - loss: 0.4070 - tp: 14623.0000 - fp: 6083.0000 - tn: 47440.0000 - fn: 8963.0000 - accuracy: 0.8049 - precision: 0.7062 - recall: 0.6200 - auc: 0.8699 - f1_score: 0.6597 - average_precision: 0.7070 - val_loss: 0.4175 - val_tp: 6492.0000 - val_fp: 3112.0000 - val_tn: 19893.0000 - val_fn: 3550.0000 - val_accuracy: 0.7984 - val_precision: 0.6760 - val_recall: 0.6465 - val_auc: 0.8628 - val_f1_score: 0.6654 - val_average_precision: 0.6834\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4054 - tp: 14838.0000 - fp: 6236.0000 - tn: 47287.0000 - fn: 8748.0000 - accuracy: 0.8057 - precision: 0.7041 - recall: 0.6291 - auc: 0.8710 - f1_score: 0.6645 - average_precision: 0.7047 - val_loss: 0.4175 - val_tp: 6291.0000 - val_fp: 2890.0000 - val_tn: 20115.0000 - val_fn: 3751.0000 - val_accuracy: 0.7990 - val_precision: 0.6852 - val_recall: 0.6265 - val_auc: 0.8625 - val_f1_score: 0.6589 - val_average_precision: 0.6920\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.4059 - tp: 14847.0000 - fp: 6264.0000 - tn: 47259.0000 - fn: 8739.0000 - accuracy: 0.8054 - precision: 0.7033 - recall: 0.6295 - auc: 0.8707 - f1_score: 0.6638 - average_precision: 0.7036 - val_loss: 0.4180 - val_tp: 6146.0000 - val_fp: 2751.0000 - val_tn: 20254.0000 - val_fn: 3896.0000 - val_accuracy: 0.7989 - val_precision: 0.6908 - val_recall: 0.6120 - val_auc: 0.8621 - val_f1_score: 0.6539 - val_average_precision: 0.6978\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4053 - tp: 14930.0000 - fp: 6211.0000 - tn: 47312.0000 - fn: 8656.0000 - accuracy: 0.8072 - precision: 0.7062 - recall: 0.6330 - auc: 0.8713 - f1_score: 0.6670 - average_precision: 0.7071 - val_loss: 0.4204 - val_tp: 5479.0000 - val_fp: 2177.0000 - val_tn: 20828.0000 - val_fn: 4563.0000 - val_accuracy: 0.7960 - val_precision: 0.7156 - val_recall: 0.5456 - val_auc: 0.8610 - val_f1_score: 0.6233 - val_average_precision: 0.7230\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 21s 561ms/step - loss: 0.4043 - tp: 14852.0000 - fp: 6116.0000 - tn: 47407.0000 - fn: 8734.0000 - accuracy: 0.8074 - precision: 0.7083 - recall: 0.6297 - auc: 0.8720 - f1_score: 0.6662 - average_precision: 0.7096 - val_loss: 0.4159 - val_tp: 6300.0000 - val_fp: 2861.0000 - val_tn: 20144.0000 - val_fn: 3742.0000 - val_accuracy: 0.8002 - val_precision: 0.6877 - val_recall: 0.6274 - val_auc: 0.8639 - val_f1_score: 0.6604 - val_average_precision: 0.6943\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4032 - tp: 14956.0000 - fp: 6293.0000 - tn: 47230.0000 - fn: 8630.0000 - accuracy: 0.8065 - precision: 0.7038 - recall: 0.6341 - auc: 0.8726 - f1_score: 0.6668 - average_precision: 0.7047 - val_loss: 0.4175 - val_tp: 6037.0000 - val_fp: 2596.0000 - val_tn: 20409.0000 - val_fn: 4005.0000 - val_accuracy: 0.8003 - val_precision: 0.6993 - val_recall: 0.6012 - val_auc: 0.8627 - val_f1_score: 0.6511 - val_average_precision: 0.7057\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4018 - tp: 14846.0000 - fp: 6034.0000 - tn: 47489.0000 - fn: 8740.0000 - accuracy: 0.8084 - precision: 0.7110 - recall: 0.6294 - auc: 0.8735 - f1_score: 0.6675 - average_precision: 0.7112 - val_loss: 0.4171 - val_tp: 6770.0000 - val_fp: 3385.0000 - val_tn: 19620.0000 - val_fn: 3272.0000 - val_accuracy: 0.7986 - val_precision: 0.6667 - val_recall: 0.6742 - val_auc: 0.8637 - val_f1_score: 0.6764 - val_average_precision: 0.6751\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4004 - tp: 14962.0000 - fp: 6262.0000 - tn: 47261.0000 - fn: 8624.0000 - accuracy: 0.8069 - precision: 0.7050 - recall: 0.6344 - auc: 0.8742 - f1_score: 0.6678 - average_precision: 0.7057 - val_loss: 0.4203 - val_tp: 6033.0000 - val_fp: 2649.0000 - val_tn: 20356.0000 - val_fn: 4009.0000 - val_accuracy: 0.7985 - val_precision: 0.6949 - val_recall: 0.6008 - val_auc: 0.8617 - val_f1_score: 0.6498 - val_average_precision: 0.7033\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.4003 - tp: 14851.0000 - fp: 6040.0000 - tn: 47483.0000 - fn: 8735.0000 - accuracy: 0.8084 - precision: 0.7109 - recall: 0.6297 - auc: 0.8745 - f1_score: 0.6676 - average_precision: 0.7117 - val_loss: 0.4187 - val_tp: 6266.0000 - val_fp: 2886.0000 - val_tn: 20119.0000 - val_fn: 3776.0000 - val_accuracy: 0.7984 - val_precision: 0.6847 - val_recall: 0.6240 - val_auc: 0.8624 - val_f1_score: 0.6583 - val_average_precision: 0.6933\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.3992 - tp: 15037.0000 - fp: 6151.0000 - tn: 47372.0000 - fn: 8549.0000 - accuracy: 0.8094 - precision: 0.7097 - recall: 0.6375 - auc: 0.8752 - f1_score: 0.6714 - average_precision: 0.7100 - val_loss: 0.4162 - val_tp: 6250.0000 - val_fp: 2793.0000 - val_tn: 20212.0000 - val_fn: 3792.0000 - val_accuracy: 0.8007 - val_precision: 0.6911 - val_recall: 0.6224 - val_auc: 0.8638 - val_f1_score: 0.6601 - val_average_precision: 0.6988\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.3982 - tp: 14898.0000 - fp: 6040.0000 - tn: 47483.0000 - fn: 8688.0000 - accuracy: 0.8090 - precision: 0.7115 - recall: 0.6316 - auc: 0.8760 - f1_score: 0.6687 - average_precision: 0.7122 - val_loss: 0.4174 - val_tp: 5895.0000 - val_fp: 2563.0000 - val_tn: 20442.0000 - val_fn: 4147.0000 - val_accuracy: 0.7970 - val_precision: 0.6970 - val_recall: 0.5870 - val_auc: 0.8621 - val_f1_score: 0.6416 - val_average_precision: 0.7033\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3984 - tp: 14903.0000 - fp: 6098.0000 - tn: 47425.0000 - fn: 8683.0000 - accuracy: 0.8083 - precision: 0.7096 - recall: 0.6319 - auc: 0.8757 - f1_score: 0.6682 - average_precision: 0.7106 - val_loss: 0.4166 - val_tp: 6198.0000 - val_fp: 2847.0000 - val_tn: 20158.0000 - val_fn: 3844.0000 - val_accuracy: 0.7975 - val_precision: 0.6852 - val_recall: 0.6172 - val_auc: 0.8624 - val_f1_score: 0.6545 - val_average_precision: 0.6931\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.3980 - tp: 15078.0000 - fp: 6105.0000 - tn: 47418.0000 - fn: 8508.0000 - accuracy: 0.8105 - precision: 0.7118 - recall: 0.6393 - auc: 0.8762 - f1_score: 0.6735 - average_precision: 0.7127 - val_loss: 0.4177 - val_tp: 6372.0000 - val_fp: 2969.0000 - val_tn: 20036.0000 - val_fn: 3670.0000 - val_accuracy: 0.7991 - val_precision: 0.6822 - val_recall: 0.6345 - val_auc: 0.8625 - val_f1_score: 0.6635 - val_average_precision: 0.6892\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3963 - tp: 15057.0000 - fp: 6140.0000 - tn: 47383.0000 - fn: 8529.0000 - accuracy: 0.8098 - precision: 0.7103 - recall: 0.6384 - auc: 0.8771 - f1_score: 0.6721 - average_precision: 0.7120 - val_loss: 0.4177 - val_tp: 5990.0000 - val_fp: 2617.0000 - val_tn: 20388.0000 - val_fn: 4052.0000 - val_accuracy: 0.7982 - val_precision: 0.6959 - val_recall: 0.5965 - val_auc: 0.8630 - val_f1_score: 0.6480 - val_average_precision: 0.7039\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.3939 - tp: 15203.0000 - fp: 6123.0000 - tn: 47400.0000 - fn: 8383.0000 - accuracy: 0.8119 - precision: 0.7129 - recall: 0.6446 - auc: 0.8790 - f1_score: 0.6766 - average_precision: 0.7136 - val_loss: 0.4222 - val_tp: 5407.0000 - val_fp: 2107.0000 - val_tn: 20898.0000 - val_fn: 4635.0000 - val_accuracy: 0.7960 - val_precision: 0.7196 - val_recall: 0.5384 - val_auc: 0.8624 - val_f1_score: 0.6207 - val_average_precision: 0.7269\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3948 - tp: 15027.0000 - fp: 5957.0000 - tn: 47566.0000 - fn: 8559.0000 - accuracy: 0.8117 - precision: 0.7161 - recall: 0.6371 - auc: 0.8784 - f1_score: 0.6742 - average_precision: 0.7179 - val_loss: 0.4159 - val_tp: 6489.0000 - val_fp: 3097.0000 - val_tn: 19908.0000 - val_fn: 3553.0000 - val_accuracy: 0.7988 - val_precision: 0.6769 - val_recall: 0.6462 - val_auc: 0.8638 - val_f1_score: 0.6658 - val_average_precision: 0.6833\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3940 - tp: 15113.0000 - fp: 6051.0000 - tn: 47472.0000 - fn: 8473.0000 - accuracy: 0.8116 - precision: 0.7141 - recall: 0.6408 - auc: 0.8788 - f1_score: 0.6750 - average_precision: 0.7143 - val_loss: 0.4173 - val_tp: 6011.0000 - val_fp: 2605.0000 - val_tn: 20400.0000 - val_fn: 4031.0000 - val_accuracy: 0.7992 - val_precision: 0.6977 - val_recall: 0.5986 - val_auc: 0.8623 - val_f1_score: 0.6506 - val_average_precision: 0.7056\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.3937 - tp: 15156.0000 - fp: 6078.0000 - tn: 47445.0000 - fn: 8430.0000 - accuracy: 0.8119 - precision: 0.7138 - recall: 0.6426 - auc: 0.8792 - f1_score: 0.6760 - average_precision: 0.7144 - val_loss: 0.4167 - val_tp: 6023.0000 - val_fp: 2676.0000 - val_tn: 20329.0000 - val_fn: 4019.0000 - val_accuracy: 0.7974 - val_precision: 0.6924 - val_recall: 0.5998 - val_auc: 0.8630 - val_f1_score: 0.6479 - val_average_precision: 0.7004\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3915 - tp: 15289.0000 - fp: 5983.0000 - tn: 47540.0000 - fn: 8297.0000 - accuracy: 0.8148 - precision: 0.7187 - recall: 0.6482 - auc: 0.8808 - f1_score: 0.6815 - average_precision: 0.7192 - val_loss: 0.4166 - val_tp: 5727.0000 - val_fp: 2367.0000 - val_tn: 20638.0000 - val_fn: 4315.0000 - val_accuracy: 0.7978 - val_precision: 0.7076 - val_recall: 0.5703 - val_auc: 0.8638 - val_f1_score: 0.6358 - val_average_precision: 0.7133\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3903 - tp: 15183.0000 - fp: 5946.0000 - tn: 47577.0000 - fn: 8403.0000 - accuracy: 0.8139 - precision: 0.7186 - recall: 0.6437 - auc: 0.8813 - f1_score: 0.6780 - average_precision: 0.7192 - val_loss: 0.4205 - val_tp: 5545.0000 - val_fp: 2274.0000 - val_tn: 20731.0000 - val_fn: 4497.0000 - val_accuracy: 0.7951 - val_precision: 0.7092 - val_recall: 0.5522 - val_auc: 0.8611 - val_f1_score: 0.6252 - val_average_precision: 0.7157\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 21s 561ms/step - loss: 0.3912 - tp: 15137.0000 - fp: 5973.0000 - tn: 47550.0000 - fn: 8449.0000 - accuracy: 0.8130 - precision: 0.7171 - recall: 0.6418 - auc: 0.8808 - f1_score: 0.6763 - average_precision: 0.7182 - val_loss: 0.4165 - val_tp: 5995.0000 - val_fp: 2594.0000 - val_tn: 20411.0000 - val_fn: 4047.0000 - val_accuracy: 0.7990 - val_precision: 0.6980 - val_recall: 0.5970 - val_auc: 0.8637 - val_f1_score: 0.6489 - val_average_precision: 0.7063\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.3899 - tp: 15266.0000 - fp: 5932.0000 - tn: 47591.0000 - fn: 8320.0000 - accuracy: 0.8152 - precision: 0.7202 - recall: 0.6472 - auc: 0.8817 - f1_score: 0.6817 - average_precision: 0.7212 - val_loss: 0.4219 - val_tp: 6553.0000 - val_fp: 3318.0000 - val_tn: 19687.0000 - val_fn: 3489.0000 - val_accuracy: 0.7940 - val_precision: 0.6639 - val_recall: 0.6526 - val_auc: 0.8599 - val_f1_score: 0.6625 - val_average_precision: 0.6709\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.3890 - tp: 15255.0000 - fp: 5919.0000 - tn: 47604.0000 - fn: 8331.0000 - accuracy: 0.8152 - precision: 0.7205 - recall: 0.6468 - auc: 0.8824 - f1_score: 0.6809 - average_precision: 0.7218 - val_loss: 0.4202 - val_tp: 5854.0000 - val_fp: 2523.0000 - val_tn: 20482.0000 - val_fn: 4188.0000 - val_accuracy: 0.7969 - val_precision: 0.6988 - val_recall: 0.5830 - val_auc: 0.8617 - val_f1_score: 0.6405 - val_average_precision: 0.7075\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3877 - tp: 15390.0000 - fp: 6015.0000 - tn: 47508.0000 - fn: 8196.0000 - accuracy: 0.8157 - precision: 0.7190 - recall: 0.6525 - auc: 0.8832 - f1_score: 0.6839 - average_precision: 0.7198 - val_loss: 0.4200 - val_tp: 5816.0000 - val_fp: 2487.0000 - val_tn: 20518.0000 - val_fn: 4226.0000 - val_accuracy: 0.7969 - val_precision: 0.7005 - val_recall: 0.5792 - val_auc: 0.8629 - val_f1_score: 0.6376 - val_average_precision: 0.7081\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.3850 - tp: 15319.0000 - fp: 5817.0000 - tn: 47706.0000 - fn: 8267.0000 - accuracy: 0.8173 - precision: 0.7248 - recall: 0.6495 - auc: 0.8849 - f1_score: 0.6847 - average_precision: 0.7251 - val_loss: 0.4206 - val_tp: 6166.0000 - val_fp: 2766.0000 - val_tn: 20239.0000 - val_fn: 3876.0000 - val_accuracy: 0.7990 - val_precision: 0.6903 - val_recall: 0.6140 - val_auc: 0.8614 - val_f1_score: 0.6545 - val_average_precision: 0.6968\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3841 - tp: 15502.0000 - fp: 5944.0000 - tn: 47579.0000 - fn: 8084.0000 - accuracy: 0.8181 - precision: 0.7228 - recall: 0.6573 - auc: 0.8857 - f1_score: 0.6883 - average_precision: 0.7237 - val_loss: 0.4203 - val_tp: 6322.0000 - val_fp: 3039.0000 - val_tn: 19966.0000 - val_fn: 3720.0000 - val_accuracy: 0.7955 - val_precision: 0.6754 - val_recall: 0.6296 - val_auc: 0.8615 - val_f1_score: 0.6555 - val_average_precision: 0.6819\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 21s 561ms/step - loss: 0.3828 - tp: 15297.0000 - fp: 5853.0000 - tn: 47670.0000 - fn: 8289.0000 - accuracy: 0.8166 - precision: 0.7233 - recall: 0.6486 - auc: 0.8863 - f1_score: 0.6834 - average_precision: 0.7237 - val_loss: 0.4213 - val_tp: 6227.0000 - val_fp: 2938.0000 - val_tn: 20067.0000 - val_fn: 3815.0000 - val_accuracy: 0.7957 - val_precision: 0.6794 - val_recall: 0.6201 - val_auc: 0.8611 - val_f1_score: 0.6530 - val_average_precision: 0.6881\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3831 - tp: 15464.0000 - fp: 5942.0000 - tn: 47581.0000 - fn: 8122.0000 - accuracy: 0.8176 - precision: 0.7224 - recall: 0.6556 - auc: 0.8862 - f1_score: 0.6873 - average_precision: 0.7232 - val_loss: 0.4226 - val_tp: 6521.0000 - val_fp: 3172.0000 - val_tn: 19833.0000 - val_fn: 3521.0000 - val_accuracy: 0.7975 - val_precision: 0.6728 - val_recall: 0.6494 - val_auc: 0.8629 - val_f1_score: 0.6659 - val_average_precision: 0.6796\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.3815 - tp: 15452.0000 - fp: 5770.0000 - tn: 47753.0000 - fn: 8134.0000 - accuracy: 0.8197 - precision: 0.7281 - recall: 0.6551 - auc: 0.8874 - f1_score: 0.6894 - average_precision: 0.7289 - val_loss: 0.4218 - val_tp: 6038.0000 - val_fp: 2681.0000 - val_tn: 20324.0000 - val_fn: 4004.0000 - val_accuracy: 0.7977 - val_precision: 0.6925 - val_recall: 0.6013 - val_auc: 0.8614 - val_f1_score: 0.6507 - val_average_precision: 0.7021\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3815 - tp: 15508.0000 - fp: 5886.0000 - tn: 47637.0000 - fn: 8078.0000 - accuracy: 0.8189 - precision: 0.7249 - recall: 0.6575 - auc: 0.8872 - f1_score: 0.6891 - average_precision: 0.7252 - val_loss: 0.4232 - val_tp: 6407.0000 - val_fp: 3188.0000 - val_tn: 19817.0000 - val_fn: 3635.0000 - val_accuracy: 0.7935 - val_precision: 0.6677 - val_recall: 0.6380 - val_auc: 0.8593 - val_f1_score: 0.6581 - val_average_precision: 0.6759\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3798 - tp: 15474.0000 - fp: 5764.0000 - tn: 47759.0000 - fn: 8112.0000 - accuracy: 0.8200 - precision: 0.7286 - recall: 0.6561 - auc: 0.8882 - f1_score: 0.6899 - average_precision: 0.7307 - val_loss: 0.4231 - val_tp: 5774.0000 - val_fp: 2452.0000 - val_tn: 20553.0000 - val_fn: 4268.0000 - val_accuracy: 0.7967 - val_precision: 0.7019 - val_recall: 0.5750 - val_auc: 0.8616 - val_f1_score: 0.6376 - val_average_precision: 0.7106\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3791 - tp: 15621.0000 - fp: 5747.0000 - tn: 47776.0000 - fn: 7965.0000 - accuracy: 0.8222 - precision: 0.7310 - recall: 0.6623 - auc: 0.8890 - f1_score: 0.6949 - average_precision: 0.7319 - val_loss: 0.4232 - val_tp: 6138.0000 - val_fp: 2790.0000 - val_tn: 20215.0000 - val_fn: 3904.0000 - val_accuracy: 0.7974 - val_precision: 0.6875 - val_recall: 0.6112 - val_auc: 0.8610 - val_f1_score: 0.6533 - val_average_precision: 0.6966\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3772 - tp: 15637.0000 - fp: 5823.0000 - tn: 47700.0000 - fn: 7949.0000 - accuracy: 0.8214 - precision: 0.7287 - recall: 0.6630 - auc: 0.8900 - f1_score: 0.6937 - average_precision: 0.7291 - val_loss: 0.4226 - val_tp: 6027.0000 - val_fp: 2729.0000 - val_tn: 20276.0000 - val_fn: 4015.0000 - val_accuracy: 0.7959 - val_precision: 0.6883 - val_recall: 0.6002 - val_auc: 0.8607 - val_f1_score: 0.6462 - val_average_precision: 0.6967\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 21s 562ms/step - loss: 0.3763 - tp: 15533.0000 - fp: 5689.0000 - tn: 47834.0000 - fn: 8053.0000 - accuracy: 0.8218 - precision: 0.7319 - recall: 0.6586 - auc: 0.8906 - f1_score: 0.6927 - average_precision: 0.7335 - val_loss: 0.4267 - val_tp: 6061.0000 - val_fp: 2733.0000 - val_tn: 20272.0000 - val_fn: 3981.0000 - val_accuracy: 0.7968 - val_precision: 0.6892 - val_recall: 0.6036 - val_auc: 0.8607 - val_f1_score: 0.6492 - val_average_precision: 0.6971\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3778 - tp: 15749.0000 - fp: 5892.0000 - tn: 47631.0000 - fn: 7837.0000 - accuracy: 0.8220 - precision: 0.7277 - recall: 0.6677 - auc: 0.8898 - f1_score: 0.6958 - average_precision: 0.7299Restoring model weights from the end of the best epoch.\n",
      "38/38 [==============================] - 21s 560ms/step - loss: 0.3778 - tp: 15749.0000 - fp: 5892.0000 - tn: 47631.0000 - fn: 7837.0000 - accuracy: 0.8220 - precision: 0.7277 - recall: 0.6677 - auc: 0.8898 - f1_score: 0.6958 - average_precision: 0.7299 - val_loss: 0.4238 - val_tp: 6247.0000 - val_fp: 2913.0000 - val_tn: 20092.0000 - val_fn: 3795.0000 - val_accuracy: 0.7970 - val_precision: 0.6820 - val_recall: 0.6221 - val_auc: 0.8613 - val_f1_score: 0.6559 - val_average_precision: 0.6902\n",
      "Epoch 00079: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_average_precision', \n",
    "    verbose=1,\n",
    "    patience=20,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "history1 = model.fit(train_sequence_data,train_labels,\n",
    "          epochs=200,validation_split=0.3,\n",
    "          batch_size=2048, verbose=1, callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.423817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_tp</th>\n",
       "      <td>6247.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_fp</th>\n",
       "      <td>2913.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_tn</th>\n",
       "      <td>20092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_fn</th>\n",
       "      <td>3795.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_accuracy</th>\n",
       "      <td>0.797016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_precision</th>\n",
       "      <td>0.681987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_recall</th>\n",
       "      <td>0.622087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_auc</th>\n",
       "      <td>0.861331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_f1_score</th>\n",
       "      <td>0.655933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_average_precision</th>\n",
       "      <td>0.690150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "val_loss                   0.423817\n",
       "val_tp                  6247.000000\n",
       "val_fp                  2913.000000\n",
       "val_tn                 20092.000000\n",
       "val_fn                  3795.000000\n",
       "val_accuracy               0.797016\n",
       "val_precision              0.681987\n",
       "val_recall                 0.622087\n",
       "val_auc                    0.861331\n",
       "val_f1_score               0.655933\n",
       "val_average_precision      0.690150"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('validation score:')\n",
    "val_score = {\n",
    "    'val_loss':history1.history['val_loss'][78],'val_tp':history1.history['val_tp'][78],\n",
    "    'val_fp':history1.history['val_fp'][78],'val_tn':history1.history['val_tn'][78],\n",
    "    'val_fn':history1.history['val_fn'][78],'val_accuracy':history1.history['val_accuracy'][78],\n",
    "    'val_precision':history1.history['val_precision'][78],'val_recall':history1.history['val_recall'][78],\n",
    "    'val_auc':history1.history['val_auc'][78],'val_f1_score':history1.history['val_f1_score'][78],\n",
    "    'val_average_precision':history1.history['val_average_precision'][78]\n",
    "}\n",
    "pd.DataFrame.from_dict(val_score, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 117ms/step - loss: 0.5254 - tp: 1376.0000 - fp: 587.0000 - tn: 5951.0000 - fn: 1893.0000 - accuracy: 0.7471 - precision: 0.7010 - recall: 0.4209 - auc: 0.8096 - f1_score: 0.5261 - average_precision: 0.7012\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on test data\n",
    "results = model.evaluate(test_sequence_data,test_labels, batch_size=2048, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loss</td>\n",
       "      <td>0.525374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tp</td>\n",
       "      <td>1376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fp</td>\n",
       "      <td>587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tn</td>\n",
       "      <td>5951.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fn</td>\n",
       "      <td>1893.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.747119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.700968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.420924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.809648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.526105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.701207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics       scores\n",
       "0                loss     0.525374\n",
       "1                  tp  1376.000000\n",
       "2                  fp   587.000000\n",
       "3                  tn  5951.000000\n",
       "4                  fn  1893.000000\n",
       "5            accuracy     0.747119\n",
       "6           precision     0.700968\n",
       "7              recall     0.420924\n",
       "8                 auc     0.809648\n",
       "9            f1_score     0.526105\n",
       "10  average_precision     0.701207"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Result on test data:')\n",
    "result = {'metrics':model.metrics_names, 'scores': results}\n",
    "pd.DataFrame(result, columns=['metrics','scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating the Fully connected NN model with only aux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 5)                 610       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 681\n",
      "Trainable params: 681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "# define the keras model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(5, input_dim=train_unsupervised_data.shape[1], activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "    # compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=Config.METRICS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/689 [..............................] - ETA: 59s - loss: 0.8638 - tp: 3257.0000 - fp: 4003.0000 - tn: 2710.0000 - fn: 93.0000 - accuracy: 0.5930 - precision: 0.4486 - recall: 0.9722 - auc: 0.8920 - f1_score: 0.3510 - average_precision: 0.2903WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.1677s). Check your callbacks.\n",
      "689/689 [==============================] - 5s 8ms/step - loss: 0.5865 - tp: 7626.0000 - fp: 6398.0000 - tn: 61263.0000 - fn: 22644.0000 - accuracy: 0.7034 - precision: 0.5438 - recall: 0.2519 - auc: 0.7032 - f1_score: 0.2207 - average_precision: 0.4301 - val_loss: 0.3304 - val_tp: 4605.0000 - val_fp: 55.0000 - val_tn: 15350.0000 - val_fn: 2022.0000 - val_accuracy: 0.9057 - val_precision: 0.9882 - val_recall: 0.6949 - val_auc: 0.9611 - val_f1_score: 0.8156 - val_average_precision: 0.9884\n",
      "Epoch 2/30\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3991 - tp: 13982.0000 - fp: 1154.0000 - tn: 59969.0000 - fn: 13019.0000 - accuracy: 0.8392 - precision: 0.9238 - recall: 0.5178 - auc: 0.8733 - f1_score: 0.6607 - average_precision: 0.9274 - val_loss: 0.2409 - val_tp: 4896.0000 - val_fp: 63.0000 - val_tn: 15342.0000 - val_fn: 1731.0000 - val_accuracy: 0.9186 - val_precision: 0.9873 - val_recall: 0.7388 - val_auc: 0.9673 - val_f1_score: 0.8447 - val_average_precision: 0.9874\n",
      "Epoch 3/30\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3713 - tp: 14558.0000 - fp: 1027.0000 - tn: 60096.0000 - fn: 12443.0000 - accuracy: 0.8471 - precision: 0.9341 - recall: 0.5392 - auc: 0.8865 - f1_score: 0.6801 - average_precision: 0.9367 - val_loss: 0.2022 - val_tp: 5296.0000 - val_fp: 153.0000 - val_tn: 15252.0000 - val_fn: 1331.0000 - val_accuracy: 0.9326 - val_precision: 0.9719 - val_recall: 0.7992 - val_auc: 0.9745 - val_f1_score: 0.8761 - val_average_precision: 0.9717\n",
      "Epoch 4/30\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3541 - tp: 14867.0000 - fp: 1027.0000 - tn: 60096.0000 - fn: 12134.0000 - accuracy: 0.8507 - precision: 0.9354 - recall: 0.5506 - auc: 0.8987 - f1_score: 0.6894 - average_precision: 0.9368 - val_loss: 0.1967 - val_tp: 5383.0000 - val_fp: 105.0000 - val_tn: 15300.0000 - val_fn: 1244.0000 - val_accuracy: 0.9388 - val_precision: 0.9809 - val_recall: 0.8123 - val_auc: 0.9768 - val_f1_score: 0.8881 - val_average_precision: 0.9810\n",
      "Epoch 5/30\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3379 - tp: 14790.0000 - fp: 1106.0000 - tn: 60017.0000 - fn: 12211.0000 - accuracy: 0.8489 - precision: 0.9304 - recall: 0.5478 - auc: 0.9113 - f1_score: 0.6867 - average_precision: 0.9337 - val_loss: 0.1962 - val_tp: 5031.0000 - val_fp: 61.0000 - val_tn: 15344.0000 - val_fn: 1596.0000 - val_accuracy: 0.9248 - val_precision: 0.9880 - val_recall: 0.7592 - val_auc: 0.9812 - val_f1_score: 0.8581 - val_average_precision: 0.9884\n",
      "Epoch 6/30\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3297 - tp: 14789.0000 - fp: 1050.0000 - tn: 60073.0000 - fn: 12212.0000 - accuracy: 0.8495 - precision: 0.9337 - recall: 0.5477 - auc: 0.9146 - f1_score: 0.6869 - average_precision: 0.9369 - val_loss: 0.1856 - val_tp: 6076.0000 - val_fp: 871.0000 - val_tn: 14534.0000 - val_fn: 551.0000 - val_accuracy: 0.9355 - val_precision: 0.8746 - val_recall: 0.9169 - val_auc: 0.9825 - val_f1_score: 0.8932 - val_average_precision: 0.8729\n",
      "Epoch 7/30\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3236 - tp: 14713.0000 - fp: 1020.0000 - tn: 60103.0000 - fn: 12288.0000 - accuracy: 0.8490 - precision: 0.9352 - recall: 0.5449 - auc: 0.9174 - f1_score: 0.6849 - average_precision: 0.9383 - val_loss: 0.1822 - val_tp: 5182.0000 - val_fp: 110.0000 - val_tn: 15295.0000 - val_fn: 1445.0000 - val_accuracy: 0.9294 - val_precision: 0.9792 - val_recall: 0.7820 - val_auc: 0.9828 - val_f1_score: 0.8690 - val_average_precision: 0.9790\n",
      "Epoch 8/30\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3185 - tp: 14822.0000 - fp: 1011.0000 - tn: 60112.0000 - fn: 12179.0000 - accuracy: 0.8503 - precision: 0.9361 - recall: 0.5489 - auc: 0.9190 - f1_score: 0.6872 - average_precision: 0.9383 - val_loss: 0.1884 - val_tp: 5675.0000 - val_fp: 217.0000 - val_tn: 15188.0000 - val_fn: 952.0000 - val_accuracy: 0.9469 - val_precision: 0.9632 - val_recall: 0.8563 - val_auc: 0.9864 - val_f1_score: 0.9059 - val_average_precision: 0.9633\n",
      "Epoch 9/30\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3165 - tp: 14796.0000 - fp: 1010.0000 - tn: 60113.0000 - fn: 12205.0000 - accuracy: 0.8500 - precision: 0.9361 - recall: 0.5480 - auc: 0.9213 - f1_score: 0.6869 - average_precision: 0.9398 - val_loss: 0.1694 - val_tp: 5904.0000 - val_fp: 513.0000 - val_tn: 14892.0000 - val_fn: 723.0000 - val_accuracy: 0.9439 - val_precision: 0.9201 - val_recall: 0.8909 - val_auc: 0.9854 - val_f1_score: 0.9042 - val_average_precision: 0.9199\n",
      "Epoch 10/30\n",
      "687/689 [============================>.] - ETA: 0s - loss: 0.3148 - tp: 14782.0000 - fp: 965.0000 - tn: 60030.0000 - fn: 12159.0000 - accuracy: 0.8508 - precision: 0.9387 - recall: 0.5487 - auc: 0.9202 - f1_score: 0.6886 - average_precision: 0.9416Restoring model weights from the end of the best epoch.\n",
      "689/689 [==============================] - 4s 6ms/step - loss: 0.3148 - tp: 14812.0000 - fp: 966.0000 - tn: 60157.0000 - fn: 12189.0000 - accuracy: 0.8507 - precision: 0.9388 - recall: 0.5486 - auc: 0.9203 - f1_score: 0.6886 - average_precision: 0.9417 - val_loss: 0.1785 - val_tp: 5356.0000 - val_fp: 95.0000 - val_tn: 15310.0000 - val_fn: 1271.0000 - val_accuracy: 0.9380 - val_precision: 0.9826 - val_recall: 0.8082 - val_auc: 0.9874 - val_f1_score: 0.8864 - val_average_precision: 0.9826\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/only_AUX\")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_average_precision', \n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "history1 = model.fit(train_unsupervised_data,train_labels,\n",
    "          epochs=30,validation_split=0.2,\n",
    "          batch_size=128, verbose=1, callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.147426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_tp</th>\n",
       "      <td>6104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_fp</th>\n",
       "      <td>585.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_tn</th>\n",
       "      <td>14820.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_fn</th>\n",
       "      <td>523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_accuracy</th>\n",
       "      <td>0.949710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_precision</th>\n",
       "      <td>0.912543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_recall</th>\n",
       "      <td>0.921080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_auc</th>\n",
       "      <td>0.989330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_f1_score</th>\n",
       "      <td>0.916346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_average_precision</th>\n",
       "      <td>0.912695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "val_loss                   0.147426\n",
       "val_tp                  6104.000000\n",
       "val_fp                   585.000000\n",
       "val_tn                 14820.000000\n",
       "val_fn                   523.000000\n",
       "val_accuracy               0.949710\n",
       "val_precision              0.912543\n",
       "val_recall                 0.921080\n",
       "val_auc                    0.989330\n",
       "val_f1_score               0.916346\n",
       "val_average_precision      0.912695"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('validation score:')\n",
    "val_score = {\n",
    "    'val_loss':history1.history['val_loss'][7],'val_tp':history1.history['val_tp'][7],\n",
    "    'val_fp':history1.history['val_fp'][7],'val_tn':history1.history['val_tn'][7],\n",
    "    'val_fn':history1.history['val_fn'][7],'val_accuracy':history1.history['val_accuracy'][7],\n",
    "    'val_precision':history1.history['val_precision'][7],'val_recall':history1.history['val_recall'][7],\n",
    "    'val_auc':history1.history['val_auc'][7],'val_f1_score':history1.history['val_f1_score'][7],\n",
    "    'val_average_precision':history1.history['val_average_precision'][7]\n",
    "}\n",
    "pd.DataFrame.from_dict(val_score, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6415 - tp: 3221.0000 - fp: 3915.0000 - tn: 2623.0000 - fn: 48.0000 - accuracy: 0.5959 - precision: 0.4514 - recall: 0.9853 - auc: 0.9017 - f1_score: 0.6184 - average_precision: 0.4517\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on test data\n",
    "results = model.evaluate(test_unsupervised_data,test_labels, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loss</td>\n",
       "      <td>0.641508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tp</td>\n",
       "      <td>3221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fp</td>\n",
       "      <td>3915.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tn</td>\n",
       "      <td>2623.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fn</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.595901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.451373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.985317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.901682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.618395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average_precision</td>\n",
       "      <td>0.451738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metrics       scores\n",
       "0                loss     0.641508\n",
       "1                  tp  3221.000000\n",
       "2                  fp  3915.000000\n",
       "3                  tn  2623.000000\n",
       "4                  fn    48.000000\n",
       "5            accuracy     0.595901\n",
       "6           precision     0.451373\n",
       "7              recall     0.985317\n",
       "8                 auc     0.901682\n",
       "9            f1_score     0.618395\n",
       "10  average_precision     0.451738"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Result on test data:')\n",
    "result = {'metrics':model.metrics_names, 'scores': results}\n",
    "pd.DataFrame(result, columns=['metrics','scores'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('my_env': conda)",
   "language": "python",
   "name": "python38364bitmyenvconda2d692cb752374c9baa2c500ce9a95bfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
